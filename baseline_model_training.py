#!/usr/bin/env python3
"""
ğŸ† í•´ì»¤í†¤ ë² ì´ìŠ¤ë¼ì¸ ëª¨ë¸ í›ˆë ¨ ìŠ¤í¬ë¦½íŠ¸
BigQueryì—ì„œ ì €ì¥ëœ ì„ë² ë”© ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ RandomForest ë¶„ë¥˜ê¸°ë¥¼ í›ˆë ¨í•©ë‹ˆë‹¤.
"""

import pandas as pd
import numpy as np
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV
from sklearn.metrics import (
    accuracy_score, precision_score, recall_score, f1_score,
    classification_report, confusion_matrix
)
from sklearn.preprocessing import StandardScaler
import matplotlib.pyplot as plt
import seaborn as sns
from google.cloud import bigquery
import warnings
warnings.filterwarnings('ignore')

class BaselineModelTrainer:
    def __init__(self, project_id: str, dataset_id: str):
        """ë² ì´ìŠ¤ë¼ì¸ ëª¨ë¸ í›ˆë ¨ê¸° ì´ˆê¸°í™”"""
        self.project_id = project_id
        self.dataset_id = dataset_id
        self.client = bigquery.Client(project=project_id)
        self.table_id = f"{self.project_id}.{self.dataset_id}.hacker_news_embeddings_pseudo"
        
    def load_data_from_bigquery(self) -> pd.DataFrame:
        """BigQueryì—ì„œ ì„ë² ë”© ë°ì´í„° ë¡œë“œ"""
        try:
            print("ğŸ” BigQueryì—ì„œ ì„ë² ë”© ë°ì´í„° ë¡œë“œ ì¤‘...")
            
            query = f"""
            SELECT 
                id,
                title,
                text,
                combined_text,
                embedding
            FROM `{self.table_id}`
            ORDER BY id
            """
            
            df = self.client.query(query).to_dataframe()
            print(f"âœ… ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(df)}ê°œ í–‰")
            print(f"ğŸ“Š ë°ì´í„° í˜•íƒœ: {df.shape}")
            print(f"ğŸ” ì»¬ëŸ¼: {list(df.columns)}")
            
            return df
            
        except Exception as e:
            print(f"âŒ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
            return pd.DataFrame()
    
    def prepare_features_and_labels(self, df: pd.DataFrame):
        """íŠ¹ì„±(X)ê³¼ ë ˆì´ë¸”(Y) ì¤€ë¹„"""
        try:
            print("\nğŸ” íŠ¹ì„±ê³¼ ë ˆì´ë¸” ì¤€ë¹„ ì¤‘...")
            
            # ì„ë² ë”© ë²¡í„°ë¥¼ íŠ¹ì„±ìœ¼ë¡œ ë³€í™˜
            embeddings = np.array(df['embedding'].tolist())
            print(f"ğŸ“Š ì„ë² ë”© ë²¡í„° í˜•íƒœ: {embeddings.shape}")
            
            # ê°€ìƒì˜ ë ˆì´ë¸” ìƒì„± (ì‹¤ì œ ëŒ€íšŒì—ì„œëŠ” ì‹¤ì œ ë ˆì´ë¸” ì‚¬ìš©)
            # ì—¬ê¸°ì„œëŠ” í…ìŠ¤íŠ¸ ê¸¸ì´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•œ ê°„ë‹¨í•œ ë¶„ë¥˜ ë¬¸ì œ ìƒì„±
            text_lengths = df['combined_text'].str.len()
            labels = (text_lengths > text_lengths.median()).astype(int)
            
            print(f"ğŸ“Š ë ˆì´ë¸” ë¶„í¬:")
            print(f"   - í´ë˜ìŠ¤ 0: {sum(labels == 0)}ê°œ")
            print(f"   - í´ë˜ìŠ¤ 1: {sum(labels == 1)}ê°œ")
            
            return embeddings, labels
            
        except Exception as e:
            print(f"âŒ íŠ¹ì„±/ë ˆì´ë¸” ì¤€ë¹„ ì‹¤íŒ¨: {str(e)}")
            return None, None
    
    def train_baseline_model(self, X, y):
        """RandomForest ë² ì´ìŠ¤ë¼ì¸ ëª¨ë¸ í›ˆë ¨"""
        try:
            print("\nğŸš€ RandomForest ë² ì´ìŠ¤ë¼ì¸ ëª¨ë¸ í›ˆë ¨ ì‹œì‘...")
            
            # ë°ì´í„° ë¶„í•  (80% í›ˆë ¨, 20% í…ŒìŠ¤íŠ¸)
            X_train, X_test, y_train, y_test = train_test_split(
                X, y, test_size=0.2, random_state=42, stratify=y
            )
            
            print(f"ğŸ“Š í›ˆë ¨ ë°ì´í„°: {X_train.shape[0]}ê°œ")
            print(f"ğŸ“Š í…ŒìŠ¤íŠ¸ ë°ì´í„°: {X_test.shape[0]}ê°œ")
            
            # ëª¨ë¸ ì´ˆê¸°í™” ë° í›ˆë ¨
            rf_model = RandomForestClassifier(
                n_estimators=100,
                max_depth=10,
                random_state=42,
                n_jobs=-1
            )
            
            print("ğŸ”„ ëª¨ë¸ í›ˆë ¨ ì¤‘...")
            rf_model.fit(X_train, y_train)
            print("âœ… ëª¨ë¸ í›ˆë ¨ ì™„ë£Œ!")
            
            # ì˜ˆì¸¡
            y_pred = rf_model.predict(X_test)
            y_pred_proba = rf_model.predict_proba(X_test)
            
            return rf_model, X_train, X_test, y_train, y_test, y_pred, y_pred_proba
            
        except Exception as e:
            print(f"âŒ ëª¨ë¸ í›ˆë ¨ ì‹¤íŒ¨: {str(e)}")
            return None, None, None, None, None, None, None
    
    def hyperparameter_tuning(self, X, y):
        """GridSearchCVë¥¼ ì‚¬ìš©í•œ í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹"""
        try:
            print("\nğŸ” í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ ì‹œì‘...")
            
            # íŒŒë¼ë¯¸í„° ê·¸ë¦¬ë“œ ì •ì˜
            param_grid = {
                'n_estimators': [50, 100, 200],
                'max_depth': [5, 10, 15, None],
                'min_samples_split': [2, 5, 10],
                'min_samples_leaf': [1, 2, 4],
                'max_features': ['sqrt', 'log2', None]
            }
            
            print(f"ğŸ“Š íƒìƒ‰í•  íŒŒë¼ë¯¸í„° ì¡°í•©: {len(param_grid['n_estimators']) * len(param_grid['max_depth']) * len(param_grid['min_samples_split']) * len(param_grid['min_samples_leaf']) * len(param_grid['max_features'])}ê°œ")
            
            # GridSearchCV ê°ì²´ ìƒì„±
            rf_base = RandomForestClassifier(random_state=42, n_jobs=-1)
            grid_search = GridSearchCV(
                estimator=rf_base,
                param_grid=param_grid,
                cv=5,
                scoring='accuracy',
                n_jobs=-1,
                verbose=1
            )
            
            print("ğŸ”„ GridSearchCV ì‹¤í–‰ ì¤‘... (ì‹œê°„ì´ ë‹¤ì†Œ ì†Œìš”ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤)")
            grid_search.fit(X, y)
            
            print("âœ… í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ ì™„ë£Œ!")
            
            # ìµœì  ê²°ê³¼ ì¶œë ¥
            print(f"\nğŸ† ìµœì  íŒŒë¼ë¯¸í„°:")
            for param, value in grid_search.best_params_.items():
                print(f"   - {param}: {value}")
            
            print(f"\nğŸ¯ ìµœì  êµì°¨ ê²€ì¦ ì ìˆ˜: {grid_search.best_score_:.4f}")
            print(f"ğŸ“Š ìµœì  ëª¨ë¸ì˜ í‘œì¤€í¸ì°¨: {grid_search.cv_results_['std_test_score'][grid_search.best_index_]:.4f}")
            
            # ìƒìœ„ 5ê°œ ê²°ê³¼ ì¶œë ¥
            print(f"\nğŸ“ˆ ìƒìœ„ 5ê°œ íŒŒë¼ë¯¸í„° ì¡°í•©:")
            cv_results = pd.DataFrame(grid_search.cv_results_)
            top_5 = cv_results.nlargest(5, 'mean_test_score')[['mean_test_score', 'std_test_score', 'params']]
            
            for i, (_, row) in enumerate(top_5.iterrows()):
                print(f"   {i+1}ìœ„: ì ìˆ˜ {row['mean_test_score']:.4f} (Â±{row['std_test_score']:.4f})")
                print(f"        íŒŒë¼ë¯¸í„°: {row['params']}")
            
            return grid_search.best_estimator_, grid_search.best_params_, grid_search.best_score_
            
        except Exception as e:
            print(f"âŒ í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ ì‹¤íŒ¨: {str(e)}")
            return None, None, None
    
    def evaluate_model(self, y_true, y_pred, y_pred_proba, X_test, y_test):
        """ëª¨ë¸ ì„±ëŠ¥ í‰ê°€"""
        try:
            print("\nğŸ“Š ëª¨ë¸ ì„±ëŠ¥ í‰ê°€ ê²°ê³¼:")
            print("=" * 50)
            
            # ê¸°ë³¸ ì„±ëŠ¥ ì§€í‘œ
            accuracy = accuracy_score(y_true, y_pred)
            precision = precision_score(y_true, y_pred, average='weighted')
            recall = recall_score(y_true, y_pred, average='weighted')
            f1 = f1_score(y_true, y_pred, average='weighted')
            
            print(f"ğŸ¯ ì •í™•ë„ (Accuracy): {accuracy:.4f}")
            print(f"ğŸ¯ ì •ë°€ë„ (Precision): {precision:.4f}")
            print(f"ğŸ¯ ì¬í˜„ìœ¨ (Recall): {recall:.4f}")
            print(f"ğŸ¯ F1-ì ìˆ˜: {f1:.4f}")
            
            # êµì°¨ ê²€ì¦
            print("\nğŸ”„ êµì°¨ ê²€ì¦ (5-fold) ê²°ê³¼:")
            cv_scores = cross_val_score(
                RandomForestClassifier(n_estimators=100, random_state=42),
                X_test, y_test, cv=5, scoring='accuracy'
            )
            print(f"   - ê° fold ì ìˆ˜: {cv_scores}")
            print(f"   - í‰ê·  ì ìˆ˜: {cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})")
            
            # ìƒì„¸ ë¶„ë¥˜ ë³´ê³ ì„œ
            print("\nğŸ“‹ ìƒì„¸ ë¶„ë¥˜ ë³´ê³ ì„œ:")
            print(classification_report(y_true, y_pred))
            
            return {
                'accuracy': accuracy,
                'precision': precision,
                'recall': recall,
                'f1': f1,
                'cv_mean': cv_scores.mean(),
                'cv_std': cv_scores.std()
            }
            
        except Exception as e:
            print(f"âŒ ëª¨ë¸ í‰ê°€ ì‹¤íŒ¨: {str(e)}")
            return None
    
    def plot_results(self, y_true, y_pred, y_pred_proba):
        """ê²°ê³¼ ì‹œê°í™”"""
        try:
            print("\nğŸ“ˆ ê²°ê³¼ ì‹œê°í™” ìƒì„± ì¤‘...")
            
            # 1. í˜¼ë™ í–‰ë ¬
            plt.figure(figsize=(12, 4))
            
            plt.subplot(1, 3, 1)
            cm = confusion_matrix(y_true, y_pred)
            sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
            plt.title('í˜¼ë™ í–‰ë ¬ (Confusion Matrix)')
            plt.ylabel('ì‹¤ì œ ê°’')
            plt.xlabel('ì˜ˆì¸¡ ê°’')
            
            # 2. ì˜ˆì¸¡ í™•ë¥  ë¶„í¬
            plt.subplot(1, 3, 2)
            plt.hist(y_pred_proba[:, 1], bins=20, alpha=0.7, color='skyblue')
            plt.title('í´ë˜ìŠ¤ 1 ì˜ˆì¸¡ í™•ë¥  ë¶„í¬')
            plt.xlabel('ì˜ˆì¸¡ í™•ë¥ ')
            plt.ylabel('ë¹ˆë„')
            
            # 3. ì„±ëŠ¥ ì§€í‘œ ë§‰ëŒ€ ê·¸ë˜í”„
            plt.subplot(1, 3, 3)
            metrics = ['ì •í™•ë„', 'ì •ë°€ë„', 'ì¬í˜„ìœ¨', 'F1-ì ìˆ˜']
            scores = [accuracy_score(y_true, y_pred), 
                     precision_score(y_true, y_pred, average='weighted'),
                     recall_score(y_true, y_pred, average='weighted'),
                     f1_score(y_true, y_pred, average='weighted')]
            
            plt.bar(metrics, scores, color=['#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4'])
            plt.title('ëª¨ë¸ ì„±ëŠ¥ ì§€í‘œ')
            plt.ylabel('ì ìˆ˜')
            plt.ylim(0, 1)
            
            # yì¶• ë ˆì´ë¸” íšŒì „
            plt.xticks(rotation=45)
            
            plt.tight_layout()
            plt.savefig('baseline_model_results.png', dpi=300, bbox_inches='tight')
            print("âœ… ê²°ê³¼ ì‹œê°í™” ì €ì¥ ì™„ë£Œ: baseline_model_results.png")
            
        except Exception as e:
            print(f"âŒ ì‹œê°í™” ìƒì„± ì‹¤íŒ¨: {str(e)}")
    
    def run_complete_training(self):
        """ì „ì²´ í›ˆë ¨ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰"""
        print("ğŸš€ í•´ì»¤í†¤ ë² ì´ìŠ¤ë¼ì¸ ëª¨ë¸ í›ˆë ¨ ì‹œì‘!")
        print("=" * 60)
        
        # 1. ë°ì´í„° ë¡œë“œ
        df = self.load_data_from_bigquery()
        if df.empty:
            return None
        
        # 2. íŠ¹ì„±ê³¼ ë ˆì´ë¸” ì¤€ë¹„
        X, y = self.prepare_features_and_labels(df)
        if X is None:
            return None
        
        # 3. ëª¨ë¸ í›ˆë ¨
        model, X_train, X_test, y_train, y_test, y_pred, y_pred_proba = self.train_baseline_model(X, y)
        if model is None:
            return None
        
        # 4. ëª¨ë¸ í‰ê°€
        metrics = self.evaluate_model(y_test, y_pred, y_pred_proba, X_test, y_test)
        if metrics is None:
            return None
        
        # 5. ê²°ê³¼ ì‹œê°í™”
        self.plot_results(y_test, y_pred, y_pred_proba)
        
        # 6. í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹
        print("\n" + "=" * 60)
        print("ğŸ” í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ ë‹¨ê³„")
        print("=" * 60)
        
        best_model, best_params, best_score = self.hyperparameter_tuning(X, y)
        
        # 7. ìµœì¢… ìš”ì•½
        print("\n" + "=" * 60)
        print("ğŸ† ë² ì´ìŠ¤ë¼ì¸ ëª¨ë¸ í›ˆë ¨ ë° íŠœë‹ ì™„ë£Œ!")
        print("=" * 60)
        print(f"ğŸ“Š ë² ì´ìŠ¤ë¼ì¸ ëª¨ë¸ ì„±ëŠ¥:")
        print(f"   - ì •í™•ë„: {metrics['accuracy']:.4f}")
        print(f"   - F1-ì ìˆ˜: {metrics['f1']:.4f}")
        print(f"   - êµì°¨ ê²€ì¦ í‰ê· : {metrics['cv_mean']:.4f}")
        print(f"   - êµì°¨ ê²€ì¦ í‘œì¤€í¸ì°¨: {metrics['cv_std']:.4f}")
        
        if best_score:
            print(f"\nğŸ† íŠœë‹ëœ ëª¨ë¸ ì„±ëŠ¥:")
            print(f"   - ìµœì  êµì°¨ ê²€ì¦ ì ìˆ˜: {best_score:.4f}")
            print(f"   - ì„±ëŠ¥ í–¥ìƒ: {best_score - metrics['cv_mean']:.4f}")
        
        print("\nğŸ’¡ ë‹¤ìŒ ë‹¨ê³„:")
        print("   1. ë” ë§ì€ ë°ì´í„°ë¡œ ëª¨ë¸ ì¬í›ˆë ¨")
        print("   2. ê³ ê¸‰ ëª¨ë¸ ì‹¤í—˜ (ë”¥ëŸ¬ë‹, ì•™ìƒë¸”)")
        print("   3. Kaggle ì œì¶œ ì¤€ë¹„")
        
        return model, metrics, best_model, best_params, best_score

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    # ì„¤ì •
    PROJECT_ID = "persona-diary-service"
    DATASET_ID = "nebula_con_kaggle"
    
    # í›ˆë ¨ê¸° ìƒì„± ë° ì‹¤í–‰
    trainer = BaselineModelTrainer(PROJECT_ID, DATASET_ID)
    results = trainer.run_complete_training()
    
    if results:
        print("\nğŸ‰ ëª¨ë“  ì‘ì—…ì´ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
    else:
        print("\nâŒ í›ˆë ¨ ê³¼ì •ì—ì„œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    main() 