#!/usr/bin/env python3
"""
ì˜¬ë°”ë¥¸ êµ¬ë¬¸ìœ¼ë¡œ ML.GENERATE_EMBEDDING í…ŒìŠ¤íŠ¸
"""

from google.cloud import bigquery


def test_ml_generate_embedding():
    """ì˜¬ë°”ë¥¸ êµ¬ë¬¸ìœ¼ë¡œ ML.GENERATE_EMBEDDING í…ŒìŠ¤íŠ¸"""
    print("ğŸ” ì˜¬ë°”ë¥¸ êµ¬ë¬¸ìœ¼ë¡œ ML.GENERATE_EMBEDDING í…ŒìŠ¤íŠ¸ ì‹œì‘...")

    try:
        # 1. BigQuery í´ë¼ì´ì–¸íŠ¸ ìƒì„±
        print("\n1ï¸âƒ£ BigQuery í´ë¼ì´ì–¸íŠ¸ ìƒì„±...")
        client = bigquery.Client()
        print("   âœ… BigQuery í´ë¼ì´ì–¸íŠ¸ ìƒì„± ì„±ê³µ")

        # 2. ì˜¬ë°”ë¥¸ êµ¬ë¬¸ìœ¼ë¡œ ML.GENERATE_EMBEDDING í…ŒìŠ¤íŠ¸
        print("\n2ï¸âƒ£ ML.GENERATE_EMBEDDING í…ŒìŠ¤íŠ¸...")

        # ë°©ë²• 1: ML.GENERATE_EMBEDDING í•¨ìˆ˜ ì‚¬ìš©
        query1 = """
        SELECT
          ML.GENERATE_EMBEDDING(
            MODEL `persona-diary-service.nebula_con_kaggle.text_embedding_remote_model`,
            STRUCT('Hello World, this is a test sentence for BigQuery AI!' AS content)
          ) AS embedding
        """

        print("   ğŸ” ë°©ë²• 1: ML.GENERATE_EMBEDDING í•¨ìˆ˜")
        print("   ì‹¤í–‰í•  ì¿¼ë¦¬:")
        print(f"   {query1.strip()}")

        try:
            query_job = client.query(query1)
            results = query_job.result()

            for row in results:
                print("   âœ… ML.GENERATE_EMBEDDING ì„±ê³µ!")
                print("   ğŸ“Š ì„ë² ë”© ìƒì„±ë¨")
                break

        except Exception as e:
            print(f"   âŒ ë°©ë²• 1 ì‹¤íŒ¨: {str(e)[:100]}...")

            # ë°©ë²• 2: ml_generate_embedding í•¨ìˆ˜ ì‚¬ìš© (ì†Œë¬¸ì)
            print("\n   ğŸ” ë°©ë²• 2: ml_generate_embedding í•¨ìˆ˜ (ì†Œë¬¸ì)")

            query2 = """
            SELECT
              ml_generate_embedding(
                MODEL `persona-diary-service.nebula_con_kaggle.text_embedding_remote_model`,
                STRUCT('Hello World, this is a test sentence for BigQuery AI!' AS content)
              ) AS embedding
            """

            print("   ì‹¤í–‰í•  ì¿¼ë¦¬:")
            print(f"   {query2.strip()}")

            try:
                query_job = client.query(query2)
                results = query_job.result()

                for row in results:
                    print("   âœ… ml_generate_embedding ì„±ê³µ!")
                    print("   ğŸ“Š ì„ë² ë”© ìƒì„±ë¨")
                    break

            except Exception as e2:
                print(f"   âŒ ë°©ë²• 2ë„ ì‹¤íŒ¨: {str(e2)[:100]}...")

                # ë°©ë²• 3: ë‹¤ë¥¸ êµ¬ë¬¸ ì‹œë„
                print("\n   ğŸ” ë°©ë²• 3: ë‹¤ë¥¸ êµ¬ë¬¸ ì‹œë„")

                query3 = """
                SELECT
                  ML.GENERATE_EMBEDDING(
                    MODEL `persona-diary-service.nebula_con_kaggle.text_embedding_remote_model`,
                    'Hello World, this is a test sentence for BigQuery AI!'
                  ) AS embedding
                """

                print("   ì‹¤í–‰í•  ì¿¼ë¦¬:")
                print(f"   {query3.strip()}")

                try:
                    query_job = client.query(query3)
                    results = query_job.result()

                    for row in results:
                        print("   âœ… ë°©ë²• 3 ì„±ê³µ!")
                        print("   ğŸ“Š ì„ë² ë”© ìƒì„±ë¨")
                        break

                except Exception as e3:
                    print("   âŒ ëª¨ë“  ë°©ë²• ì‹¤íŒ¨")
                    print(f"   ìµœì¢… ì˜¤ë¥˜: {str(e3)[:100]}...")
                    raise e3

        print("\nâœ… ML.GENERATE_EMBEDDING í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
        return True

    except Exception as e:
        print(f"\nâŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {str(e)}")
        print(f"   ì—ëŸ¬ íƒ€ì…: {type(e).__name__}")
        return False


if __name__ == "__main__":
    test_ml_generate_embedding()
