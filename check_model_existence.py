#!/usr/bin/env python3
"""
text_embedding_remote_model ì¡´ì¬ ì—¬ë¶€ í™•ì¸
ì‚¬ë ¹ê´€ë‹˜ì˜ ì •í™•í•œ ì§„ë‹¨ ê¸°ë°˜ ëª¨ë¸ ìƒíƒœ ì ê²€
"""

from google.cloud import bigquery
from google.api_core import exceptions

def check_model_existence():
    """text_embedding_remote_model ì¡´ì¬ ì—¬ë¶€ í™•ì¸"""
    try:
        client = bigquery.Client(project='persona-diary-service')
        print("ğŸ” text_embedding_remote_model ì¡´ì¬ ì—¬ë¶€ í™•ì¸...")
        
        # ë°©ë²• 1: INFORMATION_SCHEMA.ML_MODELSì—ì„œ í™•ì¸
        query1 = """
        SELECT model_id, model_type, creation_time
        FROM `persona-diary-service.nebula_con_kaggle.INFORMATION_SCHEMA.ML_MODELS`
        WHERE model_id = 'text_embedding_remote_model'
        """
        
        try:
            result1 = client.query(query1)
            rows1 = list(result1)
            
            if rows1:
                print("âœ… text_embedding_remote_model ë°œê²¬!")
                for row in rows1:
                    print(f"  - ëª¨ë¸ ID: {row['model_id']}")
                    print(f"  - ëª¨ë¸ íƒ€ì…: {row['model_type']}")
                    print(f"  - ìƒì„± ì‹œê°„: {row['creation_time']}")
                return True
            else:
                print("âš ï¸ text_embedding_remote_modelì´ ML_MODELSì— ì—†ìŠµë‹ˆë‹¤")
                
        except Exception as e:
            print(f"âŒ ML_MODELS í™•ì¸ ì‹¤íŒ¨: {str(e)[:100]}...")
        
        # ë°©ë²• 2: ë°ì´í„°ì…‹ ë‚´ í…Œì´ë¸” ëª©ë¡ì—ì„œ í™•ì¸
        print("\nğŸ” ë°ì´í„°ì…‹ ë‚´ í…Œì´ë¸” ë° ëª¨ë¸ ëª©ë¡ í™•ì¸...")
        try:
            dataset_ref = client.dataset('nebula_con_kaggle', project='persona-diary-service')
            tables = list(client.list_tables(dataset_ref))
            
            print(f"ë°ì´í„°ì…‹ 'nebula_con_kaggle' ë‚´ í…Œì´ë¸”/ëª¨ë¸:")
            for table in tables:
                print(f"  - {table.table_id} ({table.table_type})")
                
        except Exception as e:
            print(f"âŒ ë°ì´í„°ì…‹ ëª©ë¡ í™•ì¸ ì‹¤íŒ¨: {str(e)[:100]}...")
        
        # ë°©ë²• 3: ì§ì ‘ ëª¨ë¸ í˜¸ì¶œ ì‹œë„
        print("\nğŸ” ì§ì ‘ ëª¨ë¸ í˜¸ì¶œ ì‹œë„...")
        try:
            query3 = """
            SELECT ML.GENERATE_EMBEDDING(
              MODEL `persona-diary-service.nebula_con_kaggle.text_embedding_remote_model`,
              STRUCT('test' AS content)
            ) AS embedding
            """
            
            result3 = client.query(query3)
            rows3 = list(result3)
            
            if rows3:
                print("âœ… ì§ì ‘ ëª¨ë¸ í˜¸ì¶œ ì„±ê³µ!")
                return True
            else:
                print("âš ï¸ ì§ì ‘ ëª¨ë¸ í˜¸ì¶œ ê²°ê³¼ ì—†ìŒ")
                
        except Exception as e:
            print(f"âŒ ì§ì ‘ ëª¨ë¸ í˜¸ì¶œ ì‹¤íŒ¨: {str(e)[:100]}...")
        
        return False
        
    except Exception as e:
        print(f"âŒ ëª¨ë¸ ì¡´ì¬ ì—¬ë¶€ í™•ì¸ ì˜¤ë¥˜: {str(e)}")
        return False

def check_alternative_models():
    """ëŒ€ì•ˆ ëª¨ë¸ í™•ì¸"""
    try:
        client = bigquery.Client(project='persona-diary-service')
        print("\nğŸ” ì‚¬ìš© ê°€ëŠ¥í•œ ë‹¤ë¥¸ ëª¨ë¸ í™•ì¸...")
        
        # ê³µê°œ ML ëª¨ë¸ í™•ì¸
        query = """
        SELECT model_id, model_type
        FROM `bigquery-public-data.ml_models.__TABLES__`
        WHERE table_id LIKE '%textembedding%'
        LIMIT 10
        """
        
        try:
            result = client.query(query)
            rows = list(result)
            
            if rows:
                print("âœ… ê³µê°œ ML ëª¨ë¸ ë°œê²¬:")
                for row in rows:
                    print(f"  - {row['model_id']}: {row['model_type']}")
                return True
            else:
                print("âš ï¸ ê³µê°œ ML ëª¨ë¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
                
        except Exception as e:
            print(f"âŒ ê³µê°œ ML ëª¨ë¸ í™•ì¸ ì‹¤íŒ¨: {str(e)[:100]}...")
        
        return False
        
    except Exception as e:
        print(f"âŒ ëŒ€ì•ˆ ëª¨ë¸ í™•ì¸ ì˜¤ë¥˜: {str(e)}")
        return False

def main():
    """ë©”ì¸ í™•ì¸ ì‹¤í–‰"""
    print("ğŸš€ text_embedding_remote_model ì¡´ì¬ ì—¬ë¶€ í™•ì¸ ì‹œì‘")
    print("=" * 80)
    
    # 1. ëª¨ë¸ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
    model_exists = check_model_existence()
    
    # 2. ëŒ€ì•ˆ ëª¨ë¸ í™•ì¸
    alternative_models = check_alternative_models()
    
    # ê²°ê³¼ ìš”ì•½
    print("\n" + "=" * 80)
    print("ğŸ“Š ëª¨ë¸ ì¡´ì¬ ì—¬ë¶€ í™•ì¸ ê²°ê³¼ ìš”ì•½")
    print("=" * 80)
    print(f"text_embedding_remote_model: {'âœ… ì¡´ì¬' if model_exists else 'âŒ ì¡´ì¬í•˜ì§€ ì•ŠìŒ'}")
    print(f"ëŒ€ì•ˆ ëª¨ë¸: {'âœ… ë°œê²¬' if alternative_models else 'âŒ ë°œê²¬ë˜ì§€ ì•ŠìŒ'}")
    
    if not model_exists:
        print("\nğŸš¨ í•µì‹¬ ë¬¸ì œ: text_embedding_remote_modelì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤!")
        print("ğŸ’¡ í•´ê²°ë°©ë²•:")
        print("   1. ëª¨ë¸ì„ ë¨¼ì € ìƒì„±í•´ì•¼ í•©ë‹ˆë‹¤")
        print("   2. ë˜ëŠ” ê³µê°œ ML ëª¨ë¸ì„ ì‚¬ìš©í•´ì•¼ í•©ë‹ˆë‹¤")
        print("   3. Vertex AIì—ì„œ ì›ê²© ëª¨ë¸ì„ ì—°ê²°í•´ì•¼ í•©ë‹ˆë‹¤")
    
    print("\nğŸ” ëª¨ë“  í™•ì¸ì€ ì‚¬ë ¹ê´€ë‹˜ì˜ ì •í™•í•œ ì§„ë‹¨ ê¸°ë°˜ìœ¼ë¡œ ì‹¤í–‰ë˜ì—ˆìŠµë‹ˆë‹¤")

if __name__ == "__main__":
    main() 