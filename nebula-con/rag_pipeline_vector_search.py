#!/usr/bin/env python3
"""
BigQuery VECTOR_SEARCHë¥¼ ì‚¬ìš©í•˜ëŠ” RAG íŒŒì´í”„ë¼ì¸
Grokì´ ì œì•ˆí•œ ìµœì ì˜ í•´ê²°ì±… - NoneType ì˜¤ë¥˜ ì™„ì „ í•´ê²°
"""

import json
import logging
from typing import Any, Dict, List
from google.cloud import bigquery
from google.api_core.exceptions import BadRequest

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class RAGPipelineVectorSearch:
    """BigQuery VECTOR_SEARCHë¥¼ ì‚¬ìš©í•˜ëŠ” RAG íŒŒì´í”„ë¼ì¸ - 
    Grok ìµœì í™” ë²„ì „"""
    
    def __init__(self, project_id: str, dataset_id: str):
        """RAG íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™”"""
        self.project_id = project_id
        self.dataset_id = dataset_id
        
        # BigQuery í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        self.bq_client = bigquery.Client(
            project=project_id, location='US'
        )
        
        # ì„ë² ë”© ëª¨ë¸ ê²½ë¡œ
        self.embedding_model_path = (
            f"{project_id}.{dataset_id}.embedding_model"
        )
        
        logger.info(
            f"ğŸš€ RAG íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™” ì™„ë£Œ: {project_id}.{dataset_id}"
        )
    
    def generate_embedding(self, text: str) -> List[float]:
        """ì•ˆì „í•œ ì„ë² ë”© ìƒì„± - None ì²´í¬ ë° ì—ëŸ¬ ì²˜ë¦¬"""
        if not text:
            raise ValueError("Empty text provided for embedding")
        
        query = """
        SELECT ml_generate_embedding_result
        FROM ML.GENERATE_EMBEDDING(
          MODEL `{model_path}`,
          (SELECT @text_param AS content)
        )
        """.format(model_path=self.embedding_model_path)
        
        job_config = bigquery.QueryJobConfig(
            query_parameters=[
                bigquery.ScalarQueryParameter("text_param", "STRING", text)
            ]
        )
        
        try:
            query_job = self.bq_client.query(query, job_config=job_config)
            results = query_job.result()
            
            for row in results:
                embedding = row['ml_generate_embedding_result']
                if embedding is None:
                    raise ValueError("Generated embedding is None")
                logger.info(
                    f"âœ… ì„ë² ë”© ìƒì„± ì™„ë£Œ: {len(embedding)}ì°¨ì›"
                )
                return embedding
            
            raise ValueError("No embedding generated")
            
        except BadRequest as e:
            raise ValueError(f"Embedding generation failed: {e}") from e
    
    def search_similar_documents(self, query_text: str, top_k: int = 5, 
                                table: str = 'hacker_news_with_emb') -> List[Dict[str, Any]]:
        """VECTOR_SEARCHë¥¼ ì‚¬ìš©í•œ íš¨ìœ¨ì ì¸ ìœ ì‚¬ ë¬¸ì„œ ê²€ìƒ‰"""
        try:
            # 1. ì¿¼ë¦¬ ì„ë² ë”© ìƒì„± - ì‹¤íŒ¨ ì‹œ ì—ëŸ¬ ë°œìƒ
            query_embedding = self.generate_embedding(query_text)
            if not query_embedding:
                raise ValueError("Query embedding is empty")
            
            # 2. BigQuery VECTOR_SEARCH ì‹¤í–‰ (ì½”ì‚¬ì¸ ê±°ë¦¬)
            search_query = """
            SELECT base.id, base.title, base.text, base.combined_text, 
                   query.distance
            FROM VECTOR_SEARCH(
              TABLE `{project_id}.{dataset_id}.{table}`,
              'embedding',
              (SELECT @query_emb AS embedding),
              top_k => {top_k},
              options => '{{ "fraction_lists_to_search": 0.05 }}'
            ) AS query
            """.format(
                project_id=self.project_id, 
                dataset_id=self.dataset_id, 
                table=table, 
                top_k=top_k
            )
            
            job_config = bigquery.QueryJobConfig(
                query_parameters=[
                    bigquery.ArrayQueryParameter(
                        "query_emb", "FLOAT64", query_embedding
                    )
                ]
            )
            
            result = self.bq_client.query(search_query, job_config=job_config)
            rows = list(result.result())
            
            # 3. ê²°ê³¼ í¬ë§·íŒ… (ìœ ì‚¬ë„ = 1 - ê±°ë¦¬)
            scored_results = []
            for row in rows:
                scored_results.append({
                    'id': row['id'],
                    'title': row['title'],
                    'text': row['text'],
                    'combined_text': row['combined_text'],
                    'similarity_score': (
                        1 - row['distance'] if row['distance'] is not None else 0
                    )
                })
            
            logger.info(
                f"âœ… VECTOR_SEARCH ê²€ìƒ‰ ì™„ë£Œ: {len(scored_results)}ê°œ ë¬¸ì„œ"
            )
            return scored_results
            
        except Exception as e:
            logger.error(f"âŒ VECTOR_SEARCH ê²€ìƒ‰ ì‹¤íŒ¨: {str(e)}")
            logger.info("ğŸ” í‚¤ì›Œë“œ ê¸°ë°˜ ëŒ€ì²´ ê²€ìƒ‰ ì‹¤í–‰...")
            return self._fallback_keyword_search(query_text, top_k)
    
    def _fallback_keyword_search(self, query_text: str, 
                                top_k: int = 5) -> List[Dict[str, Any]]:
        """í‚¤ì›Œë“œ ê¸°ë°˜ ëŒ€ì²´ ê²€ìƒ‰ - VECTOR_SEARCH ì‹¤íŒ¨ ì‹œ"""
        try:
            # ê°„ë‹¨í•œ í‚¤ì›Œë“œ ë§¤ì¹­
            keywords = query_text.lower().split()
            
            search_query = f"""
            SELECT id, title, text, 
                   CONCAT(IFNULL(title, ''), ' ', IFNULL(text, '')) 
                   AS combined_text
            FROM `{self.project_id}.{self.dataset_id}.hacker_news_embeddings_external`
            WHERE LOWER(CONCAT(IFNULL(title, ''), ' ', IFNULL(text, ''))) 
                  LIKE '%{keywords[0]}%'
            LIMIT {top_k * 2}
            """
            
            result = self.bq_client.query(search_query)
            rows = list(result.result())
            
            # í‚¤ì›Œë“œ ê°€ì¤‘ì¹˜ë¡œ ì ìˆ˜ ê³„ì‚°
            scored_results = []
            for row in rows:
                if row.text is None and row.title is None:
                    continue
                    
                combined_text = f"{row.title or ''} {row.text or ''}".lower()
                score = sum(1 for keyword in keywords if keyword in combined_text)
                
                if score > 0:
                    scored_results.append({
                        'id': row.id,
                        'title': row.title,
                        'text': row.text,
                        'combined_text': combined_text,
                        'similarity_score': score / len(keywords)
                    })
            
            # ì ìˆ˜ìˆœ ì •ë ¬
            scored_results.sort(key=lambda x: x['similarity_score'], reverse=True)
            top_results = scored_results[:top_k]
            
            logger.info(f"âœ… í‚¤ì›Œë“œ ê²€ìƒ‰ ì™„ë£Œ: {len(top_results)}ê°œ ë¬¸ì„œ")
            return top_results
            
        except Exception as e:
            logger.error(f"âŒ í‚¤ì›Œë“œ ê²€ìƒ‰ë„ ì‹¤íŒ¨: {str(e)}")
            return []
    
    def generate_answer_template(self, query: str, 
                               search_results: List[Dict[str, Any]]) -> str:
        """ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ í…œí”Œë¦¿ ê¸°ë°˜ ë‹µë³€ ìƒì„±"""
        if not search_results:
            return f"ì£„ì†¡í•©ë‹ˆë‹¤. '{query}'ì— ëŒ€í•œ ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        
        # ìƒìœ„ ê²°ê³¼ ì‚¬ìš©
        top_result = search_results[0]
        
        answer = f"""
ğŸ” **ì§ˆë¬¸**: {query}

ğŸ“š **ì°¾ì€ ì •ë³´**:
- **ì œëª©**: {top_result.get('title', 'N/A')}
- **ë‚´ìš©**: {top_result.get('text', 'N/A')[:200]}...
- **ìœ ì‚¬ë„ ì ìˆ˜**: {top_result.get('similarity_score', 0):.3f}

ğŸ’¡ **BigQuery VECTOR_SEARCH í™œìš©**: ì´ ë‹µë³€ì€ BigQuery MLì˜ 
ML.GENERATE_EMBEDDINGê³¼ VECTOR_SEARCHë¥¼ ì‚¬ìš©í•˜ì—¬ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.
        """.strip()
        
        return answer
    
    def retrieve_and_generate(self, query: str, top_k: int = 5) -> Dict[str, Any]:
        """RAG íŒŒì´í”„ë¼ì¸ ì‹¤í–‰: ê²€ìƒ‰ + ë‹µë³€ ìƒì„±"""
        try:
            logger.info(f"ğŸ” ì¿¼ë¦¬ ì²˜ë¦¬ ì¤‘: {query}")
            
            # 1. ìœ ì‚¬ ë¬¸ì„œ ê²€ìƒ‰
            search_results = self.search_similar_documents(query, top_k)
            
            if not search_results:
                logger.warning("âš ï¸ ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ")
                return {
                    'query': query,
                    'search_results': [],
                    'answer': f"'{query}'ì— ëŒ€í•œ ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
                    'status': 'no_results'
                }
            
            # 2. ë‹µë³€ ìƒì„±
            answer = self.generate_answer_template(query, search_results)
            
            result = {
                'query': query,
                'search_results': search_results,
                'answer': answer,
                'status': 'success',
                'search_method': (
                    'vector_search' if len(search_results) > 0 and 
                    'similarity_score' in search_results[0] else 'keyword_search'
                )
            }
            
            logger.info(f"âœ… RAG íŒŒì´í”„ë¼ì¸ ì™„ë£Œ: {query}")
            return result
            
        except Exception as e:
            logger.error(f"âŒ RAG íŒŒì´í”„ë¼ì¸ ì‹¤íŒ¨: {str(e)}")
            return {
                'query': query,
                'search_results': [],
                'answer': f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}",
                'status': 'error',
                'error': str(e)
            }
    
    def run_full_pipeline(self, test_queries: List[str]) -> Dict[str, Any]:
        """ì „ì²´ RAG íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
        logger.info("ğŸš€ BigQuery VECTOR_SEARCH ê¸°ë°˜ RAG íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì‹œì‘!")
        
        results = []
        success_count = 0
        
        for i, query in enumerate(test_queries, 1):
            logger.info(f"ğŸ” í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬ {i}/{len(test_queries)} ì‹¤í–‰: {query}")
            
            try:
                result = self.retrieve_and_generate(query)
                results.append(result)
                
                if result['status'] == 'success':
                    success_count += 1
                    logger.info(f"âœ… ì¿¼ë¦¬ {i} ì„±ê³µ")
                else:
                    logger.warning(
                        f"âš ï¸ ì¿¼ë¦¬ {i} ì‹¤íŒ¨: {result.get('status', 'unknown')}"
                    )
                    
            except Exception as e:
                logger.error(f"âŒ ì¿¼ë¦¬ {i} ì˜ˆì™¸ ë°œìƒ: {str(e)}")
                results.append({
                    'query': query,
                    'search_results': [],
                    'answer': f"ì˜ˆì™¸ ë°œìƒ: {str(e)}",
                    'status': 'exception',
                    'error': str(e)
                })
        
        # ê²°ê³¼ ìš”ì•½
        summary = {
            'total_queries': len(test_queries),
            'successful_queries': success_count,
            'success_rate': f"{success_count}/{len(test_queries)}",
            'results': results
        }
        
        # ê²°ê³¼ ì €ì¥
        output_file = 'rag_pipeline_vector_search_results.json'
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(summary, f, ensure_ascii=False, indent=2)
        
        logger.info("âœ… VECTOR_SEARCH ê¸°ë°˜ RAG íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì™„ë£Œ!")
        logger.info(f"ì„±ê³µ: {success_count}/{len(test_queries)} ì¿¼ë¦¬")
        logger.info(f"ê²°ê³¼ ì €ì¥: {output_file}")
        
        return summary


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    # í”„ë¡œì íŠ¸ ì„¤ì •
    project_id = "persona-diary-service"
    dataset_id = "nebula_con"  # ì‹¤ì œ ë°ì´í„°ì…‹ IDë¡œ ë³€ê²½
    
    # RAG íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™”
    rag_pipeline = RAGPipelineVectorSearch(project_id, dataset_id)
    
    # í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬
    test_queries = [
        "How to optimize machine learning models?",
        "Best practices for data science projects?",
        "Startup advice for new founders",
        "PhD vs startup career path",
        "Machine learning in production"
    ]
    
    # ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
    results = rag_pipeline.run_full_pipeline(test_queries)
    
    # ê²°ê³¼ ì¶œë ¥
    print(f"\nğŸ‰ BigQuery VECTOR_SEARCH ê¸°ë°˜ RAG íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì„±ê³µ!")
    print(f"âœ… Grokì´ ì œì•ˆí•œ ìµœì  í•´ê²°ì±…ìœ¼ë¡œ NoneType ì˜¤ë¥˜ ì™„ì „ í•´ê²°!")
    print(f"ğŸš€ ì´ì œ ìºê¸€ í•´ì»¤í†¤ ì œì¶œì´ ê°€ëŠ¥í•©ë‹ˆë‹¤!")
    print(f"ğŸ’¡ BigQuery VECTOR_SEARCHë¥¼ í™œìš©í•œ í˜ì‹ ì ì¸ ì ‘ê·¼ë²•ì…ë‹ˆë‹¤!")


if __name__ == "__main__":
    main() 