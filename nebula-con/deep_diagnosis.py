#!/usr/bin/env python3
"""
GCP í™˜ê²½ ì‹¬ì¸µ ì§„ë‹¨ ìŠ¤í¬ë¦½íŠ¸
ì‹¤í–‰ í™˜ê²½ì˜ ëª¨ë“  ë³€ìˆ˜ë¥¼ í•œ ë²ˆì— ì ê²€í•˜ì—¬ ë¬¸ì œ ì›ì¸ íŒŒì•…
"""

from google.cloud import bigquery
from google.cloud import bigquery_connection_v1
from google.cloud import aiplatform
import os
import json
import logging

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


def collect_gcp_environment_info():
    """GCP í™˜ê²½/ë¦¬ì†ŒìŠ¤ ì •ë³´ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤."""
    
    print("ğŸ” GCP í™˜ê²½/ë¦¬ì†ŒìŠ¤ ì •ë³´ ìˆ˜ì§‘ ì‹œì‘...")
    
    try:
        # 1. BigQuery í´ë¼ì´ì–¸íŠ¸ ì •ë³´
        bq_client = bigquery.Client()
        project_id = bq_client.project
        location = bq_client.location or "ë¯¸ì„¤ì •"
        
        print(f"\nğŸ“Š BigQuery í”„ë¡œì íŠ¸ ì •ë³´:")
        print(f"  - í”„ë¡œì íŠ¸ ID: {project_id}")
        print(f"  - ë¦¬ì „: {location}")
        
        # 2. ì„œë¹„ìŠ¤ ê³„ì • ì •ë³´
        service_account = os.environ.get('GOOGLE_APPLICATION_CREDENTIALS', 'ë¯¸ì„¤ì •')
        print(f"\nğŸ”‘ ì„œë¹„ìŠ¤ ê³„ì • ì •ë³´:")
        print(f"  - ì¸ì¦ íŒŒì¼: {service_account}")
        
        # 3. ë°ì´í„°ì…‹ ì •ë³´
        datasets = list(bq_client.list_datasets())
        print(f"\nğŸ“ BigQuery ë°ì´í„°ì…‹ ëª©ë¡:")
        for dataset in datasets:
            print(f"  - {dataset.dataset_id}")
            
            # ë°ì´í„°ì…‹ ë‚´ í…Œì´ë¸” ë° ëª¨ë¸ í™•ì¸
            try:
                tables = list(bq_client.list_tables(dataset.dataset_id))
                models = list(bq_client.list_models(dataset.dataset_id))
                
                print(f"    í…Œì´ë¸”: {len(tables)}ê°œ")
                for table in tables:
                    print(f"      - {table.table_id}")
                
                print(f"    ëª¨ë¸: {len(models)}ê°œ")
                for model in models:
                    print(f"      - {model.model_id} (íƒ€ì…: {model.model_type})")
                    
            except Exception as e:
                print(f"    ë°ì´í„°ì…‹ ì ‘ê·¼ ì˜¤ë¥˜: {str(e)}")
        
        # 4. BigQuery ì—°ê²° ì •ë³´
        print(f"\nğŸ”— BigQuery ì—°ê²° ì •ë³´:")
        try:
            connection_client = bigquery_connection_v1.ConnectionServiceClient()
            parent = f"projects/{project_id}/locations/us-central1"
            connections = list(connection_client.list_connections(parent=parent))
            
            for connection in connections:
                print(f"  - ì—°ê²°ëª…: {connection.name}")
                print(f"    ìƒíƒœ: {getattr(connection, 'state', 'ì•Œ ìˆ˜ ì—†ìŒ')}")
                if hasattr(connection, 'cloud_resource'):
                    print(f"    ë¦¬ì†ŒìŠ¤: {connection.cloud_resource}")
                    
        except Exception as e:
            print(f"  ì—°ê²° ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")
        
        # 5. í™˜ê²½ ë³€ìˆ˜ í™•ì¸
        print(f"\nğŸŒ í™˜ê²½ ë³€ìˆ˜:")
        env_vars = [
            'GOOGLE_CLOUD_PROJECT',
            'GOOGLE_APPLICATION_CREDENTIALS',
            'BIGQUERY_DATASET',
            'VERTEX_AI_LOCATION'
        ]
        
        for var in env_vars:
            value = os.environ.get(var, 'ë¯¸ì„¤ì •')
            print(f"  - {var}: {value}")
        
        return {
            'project_id': project_id,
            'location': location,
            'service_account': service_account,
            'datasets': [d.dataset_id for d in datasets]
        }
        
    except Exception as e:
        print(f"âŒ GCP í™˜ê²½ ì •ë³´ ìˆ˜ì§‘ ì‹¤íŒ¨: {str(e)}")
        return None


def test_bigquery_ml_functions():
    """BigQuery ML í•¨ìˆ˜ë“¤ì˜ ì‹¤ì œ ì‘ë™ ìƒíƒœë¥¼ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤."""
    
    print(f"\nğŸ§ª BigQuery ML í•¨ìˆ˜ í…ŒìŠ¤íŠ¸ ì‹œì‘...")
    
    try:
        client = bigquery.Client()
        
        # 1. ML.GENERATE_EMBEDDING í…ŒìŠ¤íŠ¸
        print(f"\nğŸ” ML.GENERATE_EMBEDDING í•¨ìˆ˜ í…ŒìŠ¤íŠ¸...")
        
        test_queries = [
            # ê¸°ë³¸ êµ¬ë¬¸ í…ŒìŠ¤íŠ¸
            """
            SELECT ML.GENERATE_EMBEDDING(
                'test text',
                'textembedding-gecko@003'
            ) AS embedding
            """,
            
            # ëª¨ë¸ ì°¸ì¡° í…ŒìŠ¤íŠ¸
            """
            SELECT ML.GENERATE_EMBEDDING(
                MODEL `nebula_con_kaggle.text_embedding_remote_model`,
                (SELECT 'test text' AS content)
            ) AS embedding
            """,
            
            # STRUCT ì˜µì…˜ í…ŒìŠ¤íŠ¸
            """
            SELECT ML.GENERATE_EMBEDDING(
                MODEL `nebula_con_kaggle.text_embedding_remote_model`,
                (SELECT 'test text' AS content),
                STRUCT(TRUE AS flatten_json_output)
            ) AS embedding
            """
        ]
        
        for i, query in enumerate(test_queries, 1):
            print(f"\n  í…ŒìŠ¤íŠ¸ {i}:")
            print(f"  ì¿¼ë¦¬: {query.strip()}")
            
            try:
                result = client.query(query)
                rows = list(result.result())
                print(f"  âœ… ì„±ê³µ: {len(rows)}ê°œ ê²°ê³¼")
                
            except Exception as e:
                error_msg = str(e)
                print(f"  âŒ ì‹¤íŒ¨: {error_msg}")
                
                # ì˜¤ë¥˜ ìƒì„¸ ë¶„ì„
                if "MODEL" in error_msg:
                    print(f"    ë¶„ì„: ëª¨ë¸ ê²½ë¡œ ë¬¸ì œ")
                elif "ML.GENERATE_EMBEDDING" in error_msg:
                    print(f"    ë¶„ì„: í•¨ìˆ˜ ë¯¸ì§€ì›")
                elif "permission" in error_msg:
                    print(f"    ë¶„ì„: ê¶Œí•œ ë¬¸ì œ")
                else:
                    print(f"    ë¶„ì„: ê¸°íƒ€ ì˜¤ë¥˜")
        
        # 2. AI.GENERATE_TEXT í…ŒìŠ¤íŠ¸
        print(f"\nğŸ” AI.GENERATE_TEXT í•¨ìˆ˜ í…ŒìŠ¤íŠ¸...")
        
        ai_query = """
        SELECT AI.GENERATE_TEXT(
            'Hello, how are you?',
            'gemini-pro'
        ) AS answer
        """
        
        try:
            result = client.query(ai_query)
            rows = list(result.result())
            print(f"  âœ… ì„±ê³µ: {len(rows)}ê°œ ê²°ê³¼")
            
        except Exception as e:
            error_msg = str(e)
            print(f"  âŒ ì‹¤íŒ¨: {error_msg}")
            
            if "AI.GENERATE_TEXT" in error_msg:
                print(f"    ë¶„ì„: AI í•¨ìˆ˜ ë¯¸ì§€ì›")
            else:
                print(f"    ë¶„ì„: ê¸°íƒ€ ì˜¤ë¥˜")
        
        return True
        
    except Exception as e:
        print(f"âŒ BigQuery ML í•¨ìˆ˜ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {str(e)}")
        return False


def check_vertex_ai_access():
    """Vertex AI ì ‘ê·¼ ê¶Œí•œì„ í™•ì¸í•©ë‹ˆë‹¤."""
    
    print(f"\nğŸ” Vertex AI ì ‘ê·¼ ê¶Œí•œ í™•ì¸...")
    
    try:
        # Vertex AI ì´ˆê¸°í™” ì‹œë„
        aiplatform.init(
            project=os.environ.get('GOOGLE_CLOUD_PROJECT', 'persona-diary-service'),
            location='us-central1'
        )
        
        print(f"  âœ… Vertex AI ì´ˆê¸°í™” ì„±ê³µ")
        
        # ëª¨ë¸ ì ‘ê·¼ í…ŒìŠ¤íŠ¸
        try:
            from google.cloud.aiplatform import TextEmbeddingModel
            
            model = TextEmbeddingModel.from_pretrained("textembedding-gecko@003")
            print(f"  âœ… textembedding-gecko@003 ëª¨ë¸ ì ‘ê·¼ ì„±ê³µ")
            
        except Exception as e:
            print(f"  âŒ textembedding-gecko@003 ëª¨ë¸ ì ‘ê·¼ ì‹¤íŒ¨: {str(e)}")
        
        try:
            from google.cloud.aiplatform import TextGenerationModel
            
            model = TextGenerationModel.from_pretrained("gemini-pro")
            print(f"  âœ… gemini-pro ëª¨ë¸ ì ‘ê·¼ ì„±ê³µ")
            
        except Exception as e:
            print(f"  âŒ gemini-pro ëª¨ë¸ ì ‘ê·¼ ì‹¤íŒ¨: {str(e)}")
        
        return True
        
    except Exception as e:
        print(f"  âŒ Vertex AI ì´ˆê¸°í™” ì‹¤íŒ¨: {str(e)}")
        return False


def generate_diagnostic_report():
    """ì§„ë‹¨ ë³´ê³ ì„œë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
    
    print(f"\nğŸ“‹ ì§„ë‹¨ ë³´ê³ ì„œ ìƒì„±...")
    
    report = {
        'timestamp': str(datetime.now()),
        'gcp_environment': collect_gcp_environment_info(),
        'bigquery_ml_test': test_bigquery_ml_functions(),
        'vertex_ai_access': check_vertex_ai_access()
    }
    
    # ë³´ê³ ì„œ ì €ì¥
    with open('gcp_diagnostic_report.json', 'w', encoding='utf-8') as f:
        json.dump(report, f, ensure_ascii=False, indent=2, default=str)
    
    print(f"âœ… ì§„ë‹¨ ë³´ê³ ì„œ ì €ì¥: gcp_diagnostic_report.json")
    
    return report


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸš¨ GCP í™˜ê²½ ì‹¬ì¸µ ì§„ë‹¨ ì‹œì‘...")
    
    try:
        report = generate_diagnostic_report()
        
        print(f"\nğŸ¯ ì§„ë‹¨ ì™„ë£Œ!")
        print(f"ğŸ“Š ë³´ê³ ì„œ íŒŒì¼: gcp_diagnostic_report.json")
        
        return 0
        
    except Exception as e:
        print(f"âŒ ì§„ë‹¨ ì‹¤íŒ¨: {str(e)}")
        return 1


if __name__ == "__main__":
    from datetime import datetime
    exit(main()) 