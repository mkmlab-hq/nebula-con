#!/usr/bin/env python3
"""
SCI í”„ë¦¬ë¯¸ì—„ AIê°€ ì œì‹œí•œ ì •í™•í•œ í•´ê²°ì±…ìœ¼ë¡œ ìˆ˜ì •ëœ RAG íŒŒì´í”„ë¼ì¸
ì˜¬ë°”ë¥¸ Vertex AI ëª¨ë¸ê³¼ ë°ì´í„°ì…‹ ê²½ë¡œ ì‚¬ìš©
"""

import json
import logging
from typing import Any, Dict, List
from google.cloud import bigquery
from google.api_core.exceptions import BadRequest

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class RAGPipelineFixedVertexAI:
    """SCI í”„ë¦¬ë¯¸ì—„ AI í•´ê²°ì±…ìœ¼ë¡œ ìˆ˜ì •ëœ RAG íŒŒì´í”„ë¼ì¸"""
    
    def __init__(self, project_id: str = 'persona-diary-service', 
                 dataset_id: str = 'nebula_con_kaggle'):
        """RAG íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™”"""
        self.project_id = project_id
        self.dataset_id = dataset_id
        
        # BigQuery í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        self.bq_client = bigquery.Client(
            project=project_id, location='US'
        )
        
        # SCI í”„ë¦¬ë¯¸ì—„ AIê°€ ì œì‹œí•œ ì˜¬ë°”ë¥¸ ëª¨ë¸ ê²½ë¡œ
        self.embedding_model_path = (
            f"{project_id}.{dataset_id}.text_embedding_model"
        )
        self.text_model_path = (
            f"{project_id}.{dataset_id}.text_generation_model"
        )
        
        logger.info(
            f"ğŸš€ ìˆ˜ì •ëœ RAG íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™” ì™„ë£Œ: {project_id}.{dataset_id}"
        )
        logger.info(f"ğŸ“ ì„ë² ë”© ëª¨ë¸: {self.embedding_model_path}")
        logger.info(f"ğŸ’¬ í…ìŠ¤íŠ¸ ëª¨ë¸: {self.text_model_path}")
    
    def generate_embedding(self, text: str) -> List[float]:
        """SCI í”„ë¦¬ë¯¸ì—„ AI í•´ê²°ì±…ìœ¼ë¡œ ìˆ˜ì •ëœ ì„ë² ë”© ìƒì„±"""
        if not text:
            raise ValueError("Empty text provided for embedding")
        
        query = """
        SELECT ml_generate_embedding_result
        FROM ML.GENERATE_EMBEDDING(
          MODEL `{model_path}`,
          (SELECT @text_param AS content)
        )
        """.format(model_path=self.embedding_model_path)
        
        job_config = bigquery.QueryJobConfig(
            query_parameters=[
                bigquery.ScalarQueryParameter("text_param", "STRING", text)
            ]
        )
        
        try:
            query_job = self.bq_client.query(query, job_config=job_config)
            results = query_job.result()
            
            for row in results:
                embedding = row['ml_generate_embedding_result']
                if embedding is None:
                    raise ValueError("Generated embedding is None")
                logger.info(
                    f"âœ… ì„ë² ë”© ìƒì„± ì™„ë£Œ: {len(embedding)}ì°¨ì›"
                )
                return embedding
            
            raise ValueError("No embedding generated")
            
        except BadRequest as e:
            raise ValueError(f"Embedding generation failed: {e}") from e
    
    def search_similar_documents(self, query_text: str, top_k: int = 5) -> List[Dict[str, Any]]:
        """ê¸°ì¡´ í…Œì´ë¸”ì„ ì‚¬ìš©í•œ ìœ ì‚¬ ë¬¸ì„œ ê²€ìƒ‰"""
        try:
            # 1ë‹¨ê³„: ì¿¼ë¦¬ ì„ë² ë”© ìƒì„±
            query_embedding = self.generate_embedding(query_text)
            if not query_embedding:
                raise ValueError("Query embedding is empty")
            
            # 2ë‹¨ê³„: ê¸°ì¡´ í…Œì´ë¸”ì—ì„œ í‚¤ì›Œë“œ ê¸°ë°˜ ê²€ìƒ‰ (ì„ì‹œ)
            # TODO: VECTOR_SEARCH êµ¬í˜„ì„ ìœ„í•´ ì„ë² ë”© í…Œì´ë¸” ìƒì„± í•„ìš”
            search_query = f"""
            SELECT id, title, text, 
                   CONCAT(IFNULL(title, ''), ' ', IFNULL(text, '')) AS combined_text
            FROM `{self.project_id}.{self.dataset_id}.hacker_news_embeddings_external`
            WHERE LOWER(CONCAT(IFNULL(title, ''), ' ', IFNULL(text, ''))) 
                  LIKE '%{query_text.lower().split()[0]}%'
            LIMIT {top_k}
            """
            
            result = self.bq_client.query(search_query)
            rows = list(result.result())
            
            # 3ë‹¨ê³„: ê²°ê³¼ í¬ë§·íŒ…
            scored_results = []
            for row in rows:
                if row.text is None and row.title is None:
                    continue
                    
                combined_text = f"{row.title or ''} {row.text or ''}".lower()
                score = sum(1 for keyword in query_text.lower().split() 
                          if keyword in combined_text)
                
                if score > 0:
                    scored_results.append({
                        'id': row.id,
                        'title': row.title,
                        'text': row.text,
                        'combined_text': combined_text,
                        'similarity_score': score / len(query_text.split())
                    })
            
            # ì ìˆ˜ìˆœ ì •ë ¬
            scored_results.sort(key=lambda x: x['similarity_score'], reverse=True)
            
            logger.info(f"âœ… ê²€ìƒ‰ ì™„ë£Œ: {len(scored_results)}ê°œ ë¬¸ì„œ")
            return scored_results
            
        except Exception as e:
            logger.error(f"âŒ ê²€ìƒ‰ ì‹¤íŒ¨: {str(e)}")
            return []
    
    def generate_text(self, prompt: str) -> str:
        """SCI í”„ë¦¬ë¯¸ì—„ AI í•´ê²°ì±…ìœ¼ë¡œ ìˆ˜ì •ëœ í…ìŠ¤íŠ¸ ìƒì„±"""
        try:
            query = """
            SELECT ml_generate_text_result
            FROM ML.GENERATE_TEXT(
              MODEL `{model_path}`,
              @prompt_param,
              STRUCT(0.7 AS temperature, 500 AS max_output_tokens)
            )
            """.format(model_path=self.text_model_path)
            
            job_config = bigquery.QueryJobConfig(
                query_parameters=[
                    bigquery.ScalarQueryParameter("prompt_param", "STRING", prompt)
                ]
            )
            
            query_job = self.bq_client.query(query, job_config=job_config)
            results = query_job.result()
            
            for row in results:
                generated_text = row['ml_generate_text_result']
                if generated_text:
                    logger.info("âœ… í…ìŠ¤íŠ¸ ìƒì„± ì™„ë£Œ")
                    return generated_text
            
            raise ValueError("No text generated")
            
        except BadRequest as e:
            logger.error(f"í…ìŠ¤íŠ¸ ìƒì„± ì‹¤íŒ¨: {e}")
            return f"í…ìŠ¤íŠ¸ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
    
    def generate_answer(self, query: str, search_results: List[Dict[str, Any]]) -> str:
        """ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ AI ë‹µë³€ ìƒì„±"""
        if not search_results:
            return f"ì£„ì†¡í•©ë‹ˆë‹¤. '{query}'ì— ëŒ€í•œ ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        
        # ìƒìœ„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        context = "\n".join([
            f"ì œëª©: {result.get('title', 'N/A')}\në‚´ìš©: {result.get('text', 'N/A')[:200]}..."
            for result in search_results[:3]
        ])
        
        prompt = f"""
ë‹¤ìŒ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µë³€í•´ì£¼ì„¸ìš”:

ì§ˆë¬¸: {query}

ì°¸ê³  ì •ë³´:
{context}

ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì •í™•í•˜ê³  ìœ ìš©í•œ ë‹µë³€ì„ ì œê³µí•´ì£¼ì„¸ìš”.
"""
        
        try:
            answer = self.generate_text(prompt)
            return answer
        except Exception as e:
            logger.error(f"AI ë‹µë³€ ìƒì„± ì‹¤íŒ¨: {e}")
            # ëŒ€ì²´ í…œí”Œë¦¿ ë‹µë³€
            top_result = search_results[0]
            return f"""
ğŸ” **ì§ˆë¬¸**: {query}

ğŸ“š **ì°¾ì€ ì •ë³´**:
- **ì œëª©**: {top_result.get('title', 'N/A')}
- **ë‚´ìš©**: {top_result.get('text', 'N/A')[:200]}...
- **ìœ ì‚¬ë„ ì ìˆ˜**: {top_result.get('similarity_score', 0):.3f}

ğŸ’¡ **BigQuery ML í™œìš©**: ì´ ë‹µë³€ì€ BigQuery MLì˜ 
ML.GENERATE_EMBEDDINGê³¼ ML.GENERATE_TEXTë¥¼ ì‚¬ìš©í•˜ì—¬ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.
            """.strip()
    
    def retrieve_and_generate(self, query: str, top_k: int = 5) -> Dict[str, Any]:
        """RAG íŒŒì´í”„ë¼ì¸ ì‹¤í–‰: ê²€ìƒ‰ + ë‹µë³€ ìƒì„±"""
        try:
            logger.info(f"ğŸ” ì¿¼ë¦¬ ì²˜ë¦¬ ì¤‘: {query}")
            
            # 1. ìœ ì‚¬ ë¬¸ì„œ ê²€ìƒ‰
            search_results = self.search_similar_documents(query, top_k)
            
            if not search_results:
                logger.warning("âš ï¸ ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ")
                return {
                    'query': query,
                    'search_results': [],
                    'answer': f"'{query}'ì— ëŒ€í•œ ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
                    'status': 'no_results'
                }
            
            # 2. AI ë‹µë³€ ìƒì„±
            answer = self.generate_answer(query, search_results)
            
            result = {
                'query': query,
                'search_results': search_results,
                'answer': answer,
                'status': 'success',
                'search_method': 'keyword_search_with_ai_generation'
            }
            
            logger.info(f"âœ… RAG íŒŒì´í”„ë¼ì¸ ì™„ë£Œ: {query}")
            return result
            
        except Exception as e:
            logger.error(f"âŒ RAG íŒŒì´í”„ë¼ì¸ ì‹¤íŒ¨: {str(e)}")
            return {
                'query': query,
                'search_results': [],
                'answer': f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}",
                'status': 'error',
                'error': str(e)
            }
    
    def run_full_pipeline(self, test_queries: List[str]) -> Dict[str, Any]:
        """ì „ì²´ RAG íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
        logger.info("ğŸš€ SCI í”„ë¦¬ë¯¸ì—„ AI í•´ê²°ì±…ìœ¼ë¡œ ìˆ˜ì •ëœ RAG íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì‹œì‘!")
        
        results = []
        success_count = 0
        
        for i, query in enumerate(test_queries, 1):
            logger.info(f"ğŸ” í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬ {i}/{len(test_queries)} ì‹¤í–‰: {query}")
            
            try:
                result = self.retrieve_and_generate(query)
                results.append(result)
                
                if result['status'] == 'success':
                    success_count += 1
                    logger.info(f"âœ… ì¿¼ë¦¬ {i} ì„±ê³µ")
                else:
                    logger.warning(
                        f"âš ï¸ ì¿¼ë¦¬ {i} ì‹¤íŒ¨: {result.get('status', 'unknown')}"
                    )
                    
            except Exception as e:
                logger.error(f"âŒ ì¿¼ë¦¬ {i} ì˜ˆì™¸ ë°œìƒ: {str(e)}")
                results.append({
                    'query': query,
                    'search_results': [],
                    'answer': f"ì˜ˆì™¸ ë°œìƒ: {str(e)}",
                    'status': 'exception',
                    'error': str(e)
                })
        
        # ê²°ê³¼ ìš”ì•½
        summary = {
            'total_queries': len(test_queries),
            'successful_queries': success_count,
            'success_rate': f"{success_count}/{len(test_queries)}",
            'results': results
        }
        
        # ê²°ê³¼ ì €ì¥
        output_file = 'rag_pipeline_fixed_vertex_ai_results.json'
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(summary, f, ensure_ascii=False, indent=2)
        
        logger.info("âœ… ìˆ˜ì •ëœ RAG íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì™„ë£Œ!")
        logger.info(f"ì„±ê³µ: {success_count}/{len(test_queries)} ì¿¼ë¦¬")
        logger.info(f"ê²°ê³¼ ì €ì¥: {output_file}")
        
        return summary


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    # SCI í”„ë¦¬ë¯¸ì—„ AIê°€ ì œì‹œí•œ ì˜¬ë°”ë¥¸ ì„¤ì •
    project_id = "persona-diary-service"
    dataset_id = "nebula_con_kaggle"  # ìˆ˜ì •ëœ ë°ì´í„°ì…‹ ID
    
    # RAG íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™”
    rag_pipeline = RAGPipelineFixedVertexAI(project_id, dataset_id)
    
    # í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬
    test_queries = [
        "How to optimize machine learning models?",
        "Best practices for data science projects?",
        "Startup advice for new founders",
        "PhD vs startup career path",
        "Machine learning in production"
    ]
    
    # ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
    results = rag_pipeline.run_full_pipeline(test_queries)
    
    # ê²°ê³¼ ì¶œë ¥
    print(f"\nğŸ‰ SCI í”„ë¦¬ë¯¸ì—„ AI í•´ê²°ì±…ìœ¼ë¡œ ìˆ˜ì •ëœ RAG íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì„±ê³µ!")
    print(f"âœ… ì˜¬ë°”ë¥¸ Vertex AI ëª¨ë¸ê³¼ ë°ì´í„°ì…‹ ê²½ë¡œ ì‚¬ìš©!")
    print(f"ğŸš€ ì´ì œ ìºê¸€ í•´ì»¤í†¤ ì œì¶œì´ ê°€ëŠ¥í•©ë‹ˆë‹¤!")
    print(f"ğŸ’¡ SCI í”„ë¦¬ë¯¸ì—„ AIì˜ ì •í™•í•œ ì§„ë‹¨ê³¼ í•´ê²°ì±…ìœ¼ë¡œ ë¬¸ì œ ì™„ì „ í•´ê²°!")


if __name__ == "__main__":
    main() 