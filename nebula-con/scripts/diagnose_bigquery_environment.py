#!/usr/bin/env python3
"""
BigQuery í™˜ê²½ ì¢…í•© ì§„ë‹¨ ìŠ¤í¬ë¦½íŠ¸
404 ì˜¤ë¥˜ì™€ ML ê¸°ëŠ¥ ì‹¤íŒ¨ì˜ ê·¼ë³¸ ì›ì¸ íŒŒì•…
"""

import logging
from google.cloud import bigquery
from google.api_core.exceptions import Forbidden, NotFound, BadRequest

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


def diagnose_project_access():
    """í”„ë¡œì íŠ¸ ì ‘ê·¼ ê¶Œí•œ ì§„ë‹¨"""
    try:
        client = bigquery.Client(project='persona-diary-service', location='US')
        
        logger.info("ğŸ” í”„ë¡œì íŠ¸ ì ‘ê·¼ ê¶Œí•œ ì§„ë‹¨ ì‹œì‘...")
        
        # 1. í”„ë¡œì íŠ¸ ì •ë³´ í™•ì¸
        project = client.get_project()
        logger.info(f"âœ… í”„ë¡œì íŠ¸ ì ‘ê·¼ ì„±ê³µ: {project.project_id}")
        logger.info(f"   ğŸ“ ìœ„ì¹˜: {project.location}")
        logger.info(f"   ğŸ“… ìƒì„±ì¼: {project.created}")
        
        # 2. ë°ì´í„°ì…‹ ëª©ë¡ ì¡°íšŒ ì‹œë„
        try:
            datasets = list(client.list_datasets())
            logger.info(f"âœ… ë°ì´í„°ì…‹ ëª©ë¡ ì¡°íšŒ ì„±ê³µ: {len(datasets)}ê°œ ë°œê²¬")
            
            for dataset in datasets:
                logger.info(f"   ğŸ“ {dataset.dataset_id} ({dataset.location})")
                
        except Forbidden as e:
            logger.error(f"âŒ ë°ì´í„°ì…‹ ëª©ë¡ ì¡°íšŒ ê¶Œí•œ ì—†ìŒ: {e}")
            return False
        except Exception as e:
            logger.error(f"âŒ ë°ì´í„°ì…‹ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return False
            
        return True
        
    except Exception as e:
        logger.error(f"âŒ í”„ë¡œì íŠ¸ ì ‘ê·¼ ì‹¤íŒ¨: {e}")
        return False


def diagnose_dataset_issues():
    """ë°ì´í„°ì…‹ ê´€ë ¨ ë¬¸ì œ ì§„ë‹¨"""
    try:
        client = bigquery.Client(project='persona-diary-service', location='US')
        
        logger.info("\nğŸ” ë°ì´í„°ì…‹ ë¬¸ì œ ì§„ë‹¨ ì‹œì‘...")
        
        # 1. ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ë°ì´í„°ì…‹ë“¤ í™•ì¸
        non_existent_datasets = [
            'nebula_con',
            'nebula_con_kaggle',
            'kaggle',
            'hacker_news'
        ]
        
        for dataset_id in non_existent_datasets:
            try:
                dataset_ref = client.dataset(dataset_id)
                dataset = client.get_dataset(dataset_ref)
                logger.info(f"âœ… {dataset_id}: ì¡´ì¬í•¨ ({dataset.location})")
            except NotFound:
                logger.error(f"âŒ {dataset_id}: 404 Not Found")
            except Exception as e:
                logger.error(f"âŒ {dataset_id}: ì˜¤ë¥˜ ë°œìƒ - {e}")
        
        # 2. ì‹¤ì œ ì¡´ì¬í•˜ëŠ” ë°ì´í„°ì…‹ ìƒì„¸ í™•ì¸
        try:
            # us-central1 ìœ„ì¹˜ì—ì„œ ë°ì´í„°ì…‹ í™•ì¸
            client_us_central1 = bigquery.Client(
                project='persona-diary-service', location='us-central1'
            )
            
            datasets = list(client_us_central1.list_datasets())
            logger.info(f"\nğŸ“ us-central1 ìœ„ì¹˜ ë°ì´í„°ì…‹:")
            
            for dataset in datasets:
                logger.info(f"   ğŸ“ {dataset.dataset_id}")
                
                # í…Œì´ë¸” ëª©ë¡ í™•ì¸
                try:
                    tables = list(client_us_central1.list_tables(dataset.dataset_id))
                    logger.info(f"      ğŸ“‹ í…Œì´ë¸” {len(tables)}ê°œ")
                    
                    for table in tables:
                        logger.info(f"         ğŸ—ƒï¸ {table.table_id}")
                        
                except Exception as e:
                    logger.error(f"      âŒ í…Œì´ë¸” ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {e}")
                    
        except Exception as e:
            logger.error(f"âŒ us-central1 ìœ„ì¹˜ í™•ì¸ ì‹¤íŒ¨: {e}")
            
    except Exception as e:
        logger.error(f"âŒ ë°ì´í„°ì…‹ ì§„ë‹¨ ì‹¤íŒ¨: {e}")


def diagnose_ml_capabilities():
    """BigQuery ML ê¸°ëŠ¥ ì§„ë‹¨"""
    try:
        client = bigquery.Client(project='persona-diary-service', location='US')
        
        logger.info("\nğŸ” BigQuery ML ê¸°ëŠ¥ ì§„ë‹¨ ì‹œì‘...")
        
        # 1. ML ëª¨ë¸ ëª©ë¡ í™•ì¸
        try:
            # ê¸°ë³¸ ìœ„ì¹˜ì—ì„œ ëª¨ë¸ í™•ì¸
            models = list(client.list_models())
            logger.info(f"âœ… ML ëª¨ë¸ {len(models)}ê°œ ë°œê²¬")
            
            for model in models:
                logger.info(f"   ğŸ§  {model.model_id}")
                if hasattr(model, 'model_type'):
                    logger.info(f"      íƒ€ì…: {model.model_type}")
                    
        except Exception as e:
            logger.error(f"âŒ ML ëª¨ë¸ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        
        # 2. us-central1 ìœ„ì¹˜ì—ì„œ ML ëª¨ë¸ í™•ì¸
        try:
            client_us_central1 = bigquery.Client(
                project='persona-diary-service', location='us-central1'
            )
            
            models = list(client_us_central1.list_models())
            logger.info(f"\nğŸ“ us-central1 ìœ„ì¹˜ ML ëª¨ë¸:")
            
            for model in models:
                logger.info(f"   ğŸ§  {model.model_id}")
                if hasattr(model, 'model_type'):
                    logger.info(f"      íƒ€ì…: {model.model_type}")
                    
        except Exception as e:
            logger.error(f"âŒ us-central1 ML ëª¨ë¸ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            
    except Exception as e:
        logger.error(f"âŒ ML ê¸°ëŠ¥ ì§„ë‹¨ ì‹¤íŒ¨: {e}")


def diagnose_connections():
    """BigQuery ì—°ê²° ì§„ë‹¨"""
    try:
        client = bigquery.Client(project='persona-diary-service', location='US')
        
        logger.info("\nğŸ” BigQuery ì—°ê²° ì§„ë‹¨ ì‹œì‘...")
        
        # 1. ì—°ê²° ëª©ë¡ í™•ì¸ ì‹œë„
        try:
            # ê¸°ë³¸ ìœ„ì¹˜ì—ì„œ ì—°ê²° í™•ì¸
            connections = list(client.list_connections())
            logger.info(f"âœ… ì—°ê²° {len(connections)}ê°œ ë°œê²¬")
            
            for conn in connections:
                logger.info(f"   ğŸ”Œ {conn.connection_id}")
                if hasattr(conn, 'connection_type'):
                    logger.info(f"      íƒ€ì…: {conn.connection_type}")
                    
        except Exception as e:
            logger.error(f"âŒ ì—°ê²° ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        
        # 2. us-central1 ìœ„ì¹˜ì—ì„œ ì—°ê²° í™•ì¸
        try:
            client_us_central1 = bigquery.Client(
                project='persona-diary-service', location='us-central1'
            )
            
            connections = list(client_us_central1.list_connections())
            logger.info(f"\nğŸ“ us-central1 ìœ„ì¹˜ ì—°ê²°:")
            
            for conn in connections:
                logger.info(f"   ğŸ”Œ {conn.connection_id}")
                if hasattr(conn, 'connection_type'):
                    logger.info(f"      íƒ€ì…: {conn.connection_type}")
                    
        except Exception as e:
            logger.error(f"âŒ us-central1 ì—°ê²° ì¡°íšŒ ì‹¤íŒ¨: {e}")
            
    except Exception as e:
        logger.error(f"âŒ ì—°ê²° ì§„ë‹¨ ì‹¤íŒ¨: {e}")


def test_ml_functions():
    """ML í•¨ìˆ˜ ì‹¤ì œ í…ŒìŠ¤íŠ¸"""
    try:
        client = bigquery.Client(project='persona-diary-service', location='US')
        
        logger.info("\nğŸ” ML í•¨ìˆ˜ ì‹¤ì œ í…ŒìŠ¤íŠ¸ ì‹œì‘...")
        
        # 1. ML.GENERATE_EMBEDDING í…ŒìŠ¤íŠ¸
        try:
            test_query = """
            SELECT ml_generate_embedding_result
            FROM ML.GENERATE_EMBEDDING(
              MODEL `persona-diary-service.nebula_con_kaggle.text_embedding_model`,
              (SELECT 'test text' AS content)
            )
            """
            
            logger.info("ğŸ§ª ML.GENERATE_EMBEDDING í…ŒìŠ¤íŠ¸ ì‹¤í–‰...")
            result = client.query(test_query)
            rows = list(result.result())
            
            if rows:
                logger.info("âœ… ML.GENERATE_EMBEDDING í…ŒìŠ¤íŠ¸ ì„±ê³µ!")
            else:
                logger.warning("âš ï¸ ML.GENERATE_EMBEDDING ê²°ê³¼ ì—†ìŒ")
                
        except NotFound as e:
            logger.error(f"âŒ ML.GENERATE_EMBEDDING: ëª¨ë¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ - {e}")
        except BadRequest as e:
            logger.error(f"âŒ ML.GENERATE_EMBEDDING: êµ¬ë¬¸ ì˜¤ë¥˜ - {e}")
        except Exception as e:
            logger.error(f"âŒ ML.GENERATE_EMBEDDING: ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ - {e}")
            
    except Exception as e:
        logger.error(f"âŒ ML í•¨ìˆ˜ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")


def generate_solution_report():
    """ì§„ë‹¨ ê²°ê³¼ ê¸°ë°˜ ì†”ë£¨ì…˜ ë¦¬í¬íŠ¸ ìƒì„±"""
    logger.info("\nğŸ“‹ ì§„ë‹¨ ê²°ê³¼ ê¸°ë°˜ ì†”ë£¨ì…˜ ë¦¬í¬íŠ¸")
    logger.info("=" * 50)
    
    logger.info("\nğŸš¨ ì¦‰ì‹œ í•´ê²°í•´ì•¼ í•  ë¬¸ì œë“¤:")
    logger.info("1. ë°ì´í„°ì…‹ ìœ„ì¹˜ ë¶ˆì¼ì¹˜: US vs us-central1")
    logger.info("2. ML ëª¨ë¸ ì¡´ì¬í•˜ì§€ ì•ŠìŒ")
    logger.info("3. Vertex AI ì—°ê²° ì„¤ì • ëˆ„ë½")
    logger.info("4. ê¶Œí•œ ë° ì—­í•  í™•ì¸ í•„ìš”")
    
    logger.info("\nğŸ”§ ë‹¨ê³„ë³„ í•´ê²° ë°©ì•ˆ:")
    logger.info("1ë‹¨ê³„: BigQuery ì½˜ì†”ì—ì„œ ë°ì´í„°ì…‹ ìœ„ì¹˜ í™•ì¸")
    logger.info("2ë‹¨ê³„: Vertex AI ì—°ê²° ìƒì„±")
    logger.info("3ë‹¨ê³„: ì›ê²© ML ëª¨ë¸ ìƒì„±")
    logger.info("4ë‹¨ê³„: ML í•¨ìˆ˜ í…ŒìŠ¤íŠ¸")
    
    logger.info("\nâ° ì˜ˆìƒ ì†Œìš” ì‹œê°„: 2-4ì‹œê°„")
    logger.info("ğŸ¯ ëª©í‘œ: í•´ì»¤í†¤ ì œì¶œ ê°€ëŠ¥í•œ ì™„ì „í•œ RAG íŒŒì´í”„ë¼ì¸")


if __name__ == "__main__":
    logger.info("ğŸš€ BigQuery í™˜ê²½ ì¢…í•© ì§„ë‹¨ ì‹œì‘")
    
    # 1. í”„ë¡œì íŠ¸ ì ‘ê·¼ ê¶Œí•œ ì§„ë‹¨
    if diagnose_project_access():
        # 2. ë°ì´í„°ì…‹ ë¬¸ì œ ì§„ë‹¨
        diagnose_dataset_issues()
        
        # 3. ML ê¸°ëŠ¥ ì§„ë‹¨
        diagnose_ml_capabilities()
        
        # 4. ì—°ê²° ì§„ë‹¨
        diagnose_connections()
        
        # 5. ML í•¨ìˆ˜ ì‹¤ì œ í…ŒìŠ¤íŠ¸
        test_ml_functions()
        
        # 6. ì†”ë£¨ì…˜ ë¦¬í¬íŠ¸ ìƒì„±
        generate_solution_report()
    else:
        logger.error("âŒ í”„ë¡œì íŠ¸ ì ‘ê·¼ ì‹¤íŒ¨ë¡œ ì¸í•œ ì§„ë‹¨ ì¤‘ë‹¨")
    
    logger.info("\nâœ… BigQuery í™˜ê²½ ì§„ë‹¨ ì™„ë£Œ") 