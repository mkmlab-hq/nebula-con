#!/usr/bin/env python3
"""
ìºê¸€ ëŒ€íšŒ ë°ì´í„°ì…‹ ê²½ë¡œ í™•ì¸
"""

from google.cloud import bigquery


def check_kaggle_dataset():
    """ìºê¸€ ëŒ€íšŒ ë°ì´í„°ì…‹ ê²½ë¡œ í™•ì¸"""
    print("ğŸ” ìºê¸€ ëŒ€íšŒ ë°ì´í„°ì…‹ ê²½ë¡œ í™•ì¸...")

    try:
        # 1. BigQuery í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        print("\n1ï¸âƒ£ BigQuery í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”...")
        client = bigquery.Client()
        project_id = client.project
        print(f"   âœ… í”„ë¡œì íŠ¸: {project_id}")

        # 2. ì¼ë°˜ì ì¸ ê³µê°œ ë°ì´í„°ì…‹ í…ŒìŠ¤íŠ¸
        print("\n2ï¸âƒ£ ì¼ë°˜ì ì¸ ê³µê°œ ë°ì´í„°ì…‹ í…ŒìŠ¤íŠ¸...")

        test_datasets = [
            "bigquery-public-data.utility_us.city",
            "bigquery-public-data.wikipedia.pageviews_2024",
            "bigquery-public-data.samples.shakespeare",
            "bigquery-public-data.samples.natality",
            "bigquery-public-data.samples.gsod",
        ]

        accessible_datasets = []

        for dataset_path in test_datasets:
            try:
                # ê°„ë‹¨í•œ ì¿¼ë¦¬ë¡œ ì ‘ê·¼ í…ŒìŠ¤íŠ¸
                test_query = f"SELECT 1 as test FROM `{dataset_path}` LIMIT 1"
                test_job = client.query(test_query)
                test_job.result()

                print(f"   âœ… ì ‘ê·¼ ê°€ëŠ¥: {dataset_path}")
                accessible_datasets.append(dataset_path)

                # ìŠ¤í‚¤ë§ˆ ì •ë³´ í™•ì¸
                try:
                    schema_query = f"SELECT * FROM `{dataset_path}` LIMIT 0"
                    schema_job = client.query(schema_query)
                    schema_job.result()

                    # í…Œì´ë¸” ì •ë³´ ê°€ì ¸ì˜¤ê¸°
                    table_ref = client.get_table(dataset_path)
                    print(f"      ğŸ“Š í–‰ ìˆ˜: {table_ref.num_rows:,}")
                    print(f"      ğŸ“‹ ì»¬ëŸ¼ ìˆ˜: {len(table_ref.schema)}")

                    # í…ìŠ¤íŠ¸ ì»¬ëŸ¼ ì°¾ê¸°
                    text_columns = []
                    for field in table_ref.schema:
                        if field.field_type == "STRING":
                            text_columns.append(field.name)

                    if text_columns:
                        print(f"      ğŸ“ í…ìŠ¤íŠ¸ ì»¬ëŸ¼: {', '.join(text_columns[:5])}")
                    else:
                        print("      âš ï¸ í…ìŠ¤íŠ¸ ì»¬ëŸ¼ ì—†ìŒ")

                except Exception as e:
                    print(f"      âš ï¸ ìŠ¤í‚¤ë§ˆ í™•ì¸ ì‹¤íŒ¨: {str(e)[:50]}...")

            except Exception as e:
                print(f"   âŒ ì ‘ê·¼ ë¶ˆê°€: {dataset_path} - {str(e)[:50]}...")

        # 3. ê²°ê³¼ ìš”ì•½
        print("\n3ï¸âƒ£ ê²°ê³¼ ìš”ì•½...")
        print(f"   ğŸ“Š ì ‘ê·¼ ê°€ëŠ¥í•œ ë°ì´í„°ì…‹: {len(accessible_datasets)}ê°œ")

        if accessible_datasets:
            print("   ğŸ“‹ ì‚¬ìš© ê°€ëŠ¥í•œ ë°ì´í„°ì…‹:")
            for dataset in accessible_datasets:
                print(f"      - {dataset}")

            print("\n   ğŸ’¡ ê¶Œì¥ì‚¬í•­:")
            print("      1. ìœ„ ë°ì´í„°ì…‹ ì¤‘ í•˜ë‚˜ë¥¼ ì„ íƒí•˜ì—¬ ì„ë² ë”© ìƒì„±")
            print("      2. í…ìŠ¤íŠ¸ ì»¬ëŸ¼ì´ ìˆëŠ” ë°ì´í„°ì…‹ ìš°ì„  ì„ íƒ")
            print("      3. í–‰ ìˆ˜ê°€ ì ë‹¹í•œ ë°ì´í„°ì…‹ ì„ íƒ (1000-10000í–‰)")
        else:
            print("   âš ï¸ ì ‘ê·¼ ê°€ëŠ¥í•œ ê³µê°œ ë°ì´í„°ì…‹ì´ ì—†ìŠµë‹ˆë‹¤")
            print("   ğŸ“‹ ëŒ€ì•ˆ:")
            print("      1. ìì²´ í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¡œ ê³„ì† ì§„í–‰")
            print("      2. ìºê¸€ ëŒ€íšŒ í˜ì´ì§€ì—ì„œ ì •í™•í•œ ë°ì´í„°ì…‹ ê²½ë¡œ í™•ì¸")
            print("      3. BigQuery ì½˜ì†”ì—ì„œ ì§ì ‘ ë°ì´í„°ì…‹ íƒìƒ‰")

        return accessible_datasets

    except Exception as e:
        print(f"\nâŒ ë°ì´í„°ì…‹ í™•ì¸ ì‹¤íŒ¨: {str(e)}")
        print(f"   ì—ëŸ¬ íƒ€ì…: {type(e).__name__}")
        return []


if __name__ == "__main__":
    check_kaggle_dataset()
