#!/usr/bin/env python3
"""
BigQuery Remote Model ìˆ˜ì • ìŠ¤í¬ë¦½íŠ¸ v2
ì˜¬ë°”ë¥¸ BigQuery ML êµ¬ë¬¸ìœ¼ë¡œ Remote Model ì¬ìƒì„±
"""

from google.cloud import bigquery
import logging


def recreate_remote_model_v2():
    """ì˜¬ë°”ë¥¸ BigQuery ML êµ¬ë¬¸ìœ¼ë¡œ Remote Modelì„ ì¬ìƒì„±í•©ë‹ˆë‹¤."""
    
    print("ğŸ”§ Remote Model ì¬ìƒì„± v2 ì‹œì‘...")
    
    try:
        client = bigquery.Client()
        
        # ì˜¬ë°”ë¥¸ ëª¨ë¸ ìƒì„± ì¿¼ë¦¬ (BigQuery ML ê³µì‹ ë¬¸ì„œ ê¸°ë°˜)
        create_model_query = """
        CREATE OR REPLACE MODEL `nebula_con_kaggle.text_embedding_remote_model`
        OPTIONS(
            model_type='REMOTE',
            remote_service_type='CLOUD_AI_SERVICE_V1',
            endpoint='projects/907685055657/locations/us-central1/publishers/google/models/textembedding-gecko@003'
        )
        """
        
        print("ğŸ” ëª¨ë¸ ìƒì„± ì¿¼ë¦¬ ì‹¤í–‰ ì¤‘...")
        print(f"ì¿¼ë¦¬: {create_model_query}")
        
        # ëª¨ë¸ ìƒì„±
        job = client.query(create_model_query)
        job.result()  # ì™„ë£Œ ëŒ€ê¸°
        
        print("âœ… Remote Model ì¬ìƒì„± ì™„ë£Œ!")
        
        # ëª¨ë¸ ìƒíƒœ í™•ì¸
        model_id = "text_embedding_remote_model"
        dataset_id = "nebula_con_kaggle"
        project_id = client.project
        
        model_path = f"{project_id}.{dataset_id}.{model_id}"
        
        try:
            model = client.get_model(model_path)
            print(f"\nğŸ” ì¬ìƒì„±ëœ ëª¨ë¸ ì •ë³´:")
            print(f"  - ëª¨ë¸ ID: {model.model_id}")
            print(f"  - íƒ€ì…: {model.model_type}")
            print(f"  - ìƒì„±ì¼: {model.created}")
            print(f"  - ìˆ˜ì •ì¼: {model.modified}")
            
            if hasattr(model, 'labels'):
                print(f"  - ë¼ë²¨: {model.labels}")
                
        except Exception as e:
            print(f"âŒ ëª¨ë¸ ì •ë³´ í™•ì¸ ì‹¤íŒ¨: {str(e)}")
        
        return True
        
    except Exception as e:
        print(f"âŒ Remote Model ì¬ìƒì„± ì‹¤íŒ¨: {str(e)}")
        return False


def test_model_functionality():
    """ì¬ìƒì„±ëœ ëª¨ë¸ì˜ ê¸°ëŠ¥ì„ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤."""
    
    print("\nğŸ§ª ëª¨ë¸ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹œì‘...")
    
    try:
        client = bigquery.Client()
        
        # ML.GENERATE_EMBEDDING í•¨ìˆ˜ í…ŒìŠ¤íŠ¸
        test_query = """
        SELECT 
            ML.GENERATE_EMBEDDING(
                MODEL `nebula_con_kaggle.text_embedding_remote_model`,
                (SELECT 'test text for embedding' AS content),
                STRUCT(TRUE AS flatten_json_output, 'RETRIEVAL_DOCUMENT' AS task_type)
            ) AS embedding
        LIMIT 1
        """
        
        print("ğŸ” ML.GENERATE_EMBEDDING í•¨ìˆ˜ í…ŒìŠ¤íŠ¸...")
        print(f"í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬: {test_query}")
        
        try:
            result = client.query(test_query)
            rows = list(result.result())
            print("âœ… ML.GENERATE_EMBEDDING í•¨ìˆ˜ ì •ìƒ ì‘ë™!")
            print(f"ê²°ê³¼: {len(rows)}ê°œ í–‰")
            
            # ê²°ê³¼ ìƒì„¸ í™•ì¸
            if rows:
                embedding_result = rows[0].embedding
                print(f"ì„ë² ë”© ê²°ê³¼ íƒ€ì…: {type(embedding_result)}")
                if hasattr(embedding_result, 'values'):
                    print(f"ì„ë² ë”© ì°¨ì›: {len(embedding_result.values)}")
                else:
                    print(f"ì„ë² ë”© ë‚´ìš©: {embedding_result}")
            
            return True
            
        except Exception as e:
            error_msg = str(e)
            print(f"âŒ ML.GENERATE_EMBEDDING í•¨ìˆ˜ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {error_msg}")
            
            # ì˜¤ë¥˜ ë¶„ì„
            if "MODEL" in error_msg:
                print("ğŸ” ë¶„ì„: ëª¨ë¸ ê²½ë¡œ ë˜ëŠ” ì„¤ì • ë¬¸ì œ")
            elif "connection" in error_msg:
                print("ğŸ” ë¶„ì„: Vertex AI ì—°ê²° ë¬¸ì œ")
            elif "endpoint" in error_msg:
                print("ğŸ” ë¶„ì„: ëª¨ë¸ ì—”ë“œí¬ì¸íŠ¸ ë¬¸ì œ")
            else:
                print("ğŸ” ë¶„ì„: ê¸°íƒ€ BigQuery ML ê´€ë ¨ ì˜¤ë¥˜")
            
            return False
        
    except Exception as e:
        print(f"âŒ ëª¨ë¸ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {str(e)}")
        return False


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸš¨ BigQuery Remote Model ìˆ˜ì • v2 ì‹œì‘...")
    
    try:
        # 1ë‹¨ê³„: Remote Model ì¬ìƒì„±
        if not recreate_remote_model_v2():
            print("âŒ Remote Model ì¬ìƒì„± ì‹¤íŒ¨")
            return 1
        
        # 2ë‹¨ê³„: ëª¨ë¸ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸
        if not test_model_functionality():
            print("âŒ ëª¨ë¸ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨")
            return 1
        
        print("\nğŸ‰ BigQuery Remote Model ìˆ˜ì • v2 ì™„ë£Œ!")
        print("âœ… ì´ì œ ML.GENERATE_EMBEDDING í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤!")
        
        return 0
        
    except Exception as e:
        print(f"âŒ ë©”ì¸ ì‹¤í–‰ ì˜¤ë¥˜: {str(e)}")
        return 1


if __name__ == "__main__":
    exit(main()) 