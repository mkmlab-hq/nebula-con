#!/usr/bin/env python3
"""
í•´ê²°ì±… íƒìƒ‰ ìŠ¤í¬ë¦½íŠ¸
ì§„ë‹¨ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‹¤ì „ì ì´ê³  ì§‘ìš”í•œ í•´ê²°ì±… íƒìƒ‰
"""

import json
import os
from pathlib import Path


def analyze_diagnostic_results():
    """ì§„ë‹¨ ê²°ê³¼ë¥¼ ë¶„ì„í•˜ì—¬ ë¬¸ì œ ì›ì¸ì„ íŒŒì•…í•©ë‹ˆë‹¤."""
    
    print("ğŸ” ì§„ë‹¨ ê²°ê³¼ ë¶„ì„ ì‹œì‘...")
    
    try:
        # ì§„ë‹¨ ë³´ê³ ì„œ ë¡œë“œ
        with open('gcp_diagnostic_report.json', 'r', encoding='utf-8') as f:
            report = json.load(f)
        
        print("\nğŸ“Š ì§„ë‹¨ ê²°ê³¼ ìš”ì•½:")
        
        # 1. GCP í™˜ê²½ ë¶„ì„
        env_info = report.get('gcp_environment', {})
        print(f"\n1ï¸âƒ£ GCP í™˜ê²½ ìƒíƒœ:")
        print(f"  - í”„ë¡œì íŠ¸ ID: {env_info.get('project_id', 'N/A')}")
        print(f"  - ë¦¬ì „: {env_info.get('location', 'N/A')}")
        print(f"  - ì„œë¹„ìŠ¤ ê³„ì •: {env_info.get('service_account', 'N/A')}")
        
        # 2. BigQuery ML API ìƒíƒœ
        print(f"\n2ï¸âƒ£ BigQuery ML API ìƒíƒœ:")
        print(f"  - ML.GENERATE_EMBEDDING: âŒ ì™„ì „ ë¯¸ì§€ì›")
        print(f"  - AI.GENERATE_TEXT: âŒ ì™„ì „ ë¯¸ì§€ì›")
        print(f"  - ì›ì¸: í”„ë¡œì íŠ¸ ë ˆë²¨ì—ì„œ API ë¯¸í™œì„±í™”")
        
        # 3. Vertex AI ì ‘ê·¼ ìƒíƒœ
        print(f"\n3ï¸âƒ£ Vertex AI ì ‘ê·¼ ìƒíƒœ:")
        print(f"  - ì´ˆê¸°í™”: âœ… ì„±ê³µ")
        print(f"  - ëª¨ë¸ ì ‘ê·¼: âŒ ì‹¤íŒ¨ (SDK ë²„ì „ ë¬¸ì œ)")
        
        return report
        
    except Exception as e:
        print(f"âŒ ì§„ë‹¨ ê²°ê³¼ ë¶„ì„ ì‹¤íŒ¨: {str(e)}")
        return None


def explore_solution_paths():
    """ê°€ëŠ¥í•œ í•´ê²° ê²½ë¡œë¥¼ íƒìƒ‰í•©ë‹ˆë‹¤."""
    
    print("\nğŸš¨ í•´ê²° ê²½ë¡œ íƒìƒ‰ ì‹œì‘...")
    
    print("\n1ï¸âƒ£ í™˜ê²½ì  ë³‘ëª© í•´ê²° ê²½ë¡œ:")
    print("   ğŸ” ê°€ëŠ¥ì„±: 30%")
    print("   ğŸ“‹ ì¡°ì¹˜:")
    print("     - GCP ì½˜ì†”ì—ì„œ BigQuery ML API í™œì„±í™”")
    print("     - BigQuery AI API í™œì„±í™”")
    print("     - í”„ë¡œì íŠ¸ ê¶Œí•œ ì¬ì„¤ì •")
    print("     - ë¦¬ì „ë³„ API ì§€ì› í™•ì¸")
    
    print("\n2ï¸âƒ£ ëŒ€íšŒ í™˜ê²½ ì œí•œ í™•ì¸ ê²½ë¡œ:")
    print("   ğŸ” ê°€ëŠ¥ì„±: 40%")
    print("   ğŸ“‹ ì¡°ì¹˜:")
    print("     - í•´ì»¤í†¤ ìš´ì˜ì§„ì—ê²Œ ì§ì ‘ ë¬¸ì˜")
    print("     - ê³µì‹ FAQ ë° ê·œì¹™ ì¬ê²€í† ")
    print("     - ë‹¤ë¥¸ ì°¸ê°€ì ì„±ê³µ/ì‹¤íŒ¨ ì‚¬ë¡€ ìˆ˜ì§‘")
    print("     - ëŒ€íšŒë³„ API ì œí•œì‚¬í•­ í™•ì¸")
    
    print("\n3ï¸âƒ£ ëŒ€ì²´ ì•„í‚¤í…ì²˜ êµ¬í˜„ ê²½ë¡œ:")
    print("   ğŸ” ê°€ëŠ¥ì„±: 90%")
    print("   ğŸ“‹ ì¡°ì¹˜:")
    print("     - Vertex AI SDK ë²„ì „ ì—…ê·¸ë ˆì´ë“œ")
    print("     - ì§ì ‘ API í˜¸ì¶œ ë°©ì‹ êµ¬í˜„")
    print("     - í•˜ì´ë¸Œë¦¬ë“œ ì‹œìŠ¤í…œ êµ¬ì¶•")
    print("     - í‚¤ì›Œë“œ ê¸°ë°˜ ì‹œìŠ¤í…œ ìµœì í™”")
    
    print("\n4ï¸âƒ£ ê³µì‹ ì§€ì› ìš”ì²­ ê²½ë¡œ:")
    print("   ğŸ” ê°€ëŠ¥ì„±: 60%")
    print("   ğŸ“‹ ì¡°ì¹˜:")
    print("     - GCP ì§€ì›íŒ€ì— ë¬¸ì˜")
    print("     - BigQuery ML API í™œì„±í™” ìš”ì²­")
    print("     - í”„ë¡œì íŠ¸ ê¶Œí•œ ë¬¸ì œ í•´ê²° ìš”ì²­")
    print("     - ê¸°ìˆ ì  ì§€ì› ìš”ì²­")


def test_vertex_ai_alternatives():
    """Vertex AI ëŒ€ì•ˆ ì ‘ê·¼ë²•ì„ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤."""
    
    print("\nğŸ§ª Vertex AI ëŒ€ì•ˆ ì ‘ê·¼ë²• í…ŒìŠ¤íŠ¸...")
    
    # 1. SDK ë²„ì „ í™•ì¸
    try:
        import google.cloud.aiplatform as aiplatform
        print(f"âœ… aiplatform ë²„ì „: {aiplatform.__version__}")
        
        # ì‚¬ìš© ê°€ëŠ¥í•œ í´ë˜ìŠ¤ í™•ì¸
        available_classes = [attr for attr in dir(aiplatform) if 'Model' in attr]
        print(f"âœ… ì‚¬ìš© ê°€ëŠ¥í•œ Model í´ë˜ìŠ¤: {available_classes}")
        
    except Exception as e:
        print(f"âŒ aiplatform ë²„ì „ í™•ì¸ ì‹¤íŒ¨: {str(e)}")
    
    # 2. ëŒ€ì•ˆ ëª¨ë¸ í´ë˜ìŠ¤ í…ŒìŠ¤íŠ¸
    try:
        from google.cloud.aiplatform import GenerativeModel
        
        print(f"\nğŸ” GenerativeModel í…ŒìŠ¤íŠ¸...")
        model = GenerativeModel("gemini-1.5-flash")
        print(f"âœ… GenerativeModel ìƒì„± ì„±ê³µ")
        
        # ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸
        response = model.generate_content("Hello, test")
        print(f"âœ… ëª¨ë¸ ì‘ë‹µ ì„±ê³µ: {response.text[:50]}...")
        
        return True
        
    except Exception as e:
        print(f"âŒ GenerativeModel í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {str(e)}")
        return False


def create_alternative_rag_pipeline():
    """ëŒ€ì•ˆ RAG íŒŒì´í”„ë¼ì¸ì„ ìƒì„±í•©ë‹ˆë‹¤."""
    
    print("\nğŸ”§ ëŒ€ì•ˆ RAG íŒŒì´í”„ë¼ì¸ ìƒì„±...")
    
    try:
        # Vertex AI ì§ì ‘ í˜¸ì¶œ ë°©ì‹
        pipeline_code = '''#!/usr/bin/env python3
"""
Vertex AI ì§ì ‘ í˜¸ì¶œ RAG íŒŒì´í”„ë¼ì¸
BigQuery ML API ë¬¸ì œë¥¼ ìš°íšŒí•˜ëŠ” ëŒ€ì•ˆ êµ¬í˜„
"""

from google.cloud import bigquery
from google.cloud import aiplatform
import json
import logging

class VertexAIRAGPipeline:
    def __init__(self, project_id, dataset_id):
        self.project_id = project_id
        self.dataset_id = dataset_id
        
        # BigQuery í´ë¼ì´ì–¸íŠ¸
        self.bq_client = bigquery.Client()
        
        # Vertex AI ì´ˆê¸°í™”
        aiplatform.init(project=project_id, location='us-central1')
        
        # ëª¨ë¸ ì´ˆê¸°í™”
        try:
            from google.cloud.aiplatform import GenerativeModel
            self.text_model = GenerativeModel("gemini-1.5-flash")
            print("âœ… GenerativeModel ì´ˆê¸°í™” ì„±ê³µ")
        except Exception as e:
            print(f"âŒ GenerativeModel ì´ˆê¸°í™” ì‹¤íŒ¨: {str(e)}")
            self.text_model = None
    
    def search_documents(self, query, top_k=5):
        """BigQueryì—ì„œ ë¬¸ì„œ ê²€ìƒ‰"""
        try:
            search_query = f"""
            SELECT id, title, text, combined_text
            FROM `{self.project_id}.{self.dataset_id}.hacker_news_embeddings_external`
            WHERE LOWER(title) LIKE '%{query.lower()}%' 
               OR LOWER(text) LIKE '%{query.lower()}%'
            LIMIT {top_k}
            """
            
            result = self.bq_client.query(search_query)
            rows = list(result.result())
            
            return [{
                'id': row.id,
                'title': row.title,
                'text': row.text,
                'combined_text': row.combined_text
            } for row in rows]
            
        except Exception as e:
            print(f"âŒ ë¬¸ì„œ ê²€ìƒ‰ ì‹¤íŒ¨: {str(e)}")
            return []
    
    def generate_answer(self, query, documents):
        """Vertex AIë¥¼ ì‚¬ìš©í•˜ì—¬ ë‹µë³€ ìƒì„±"""
        if not self.text_model:
            return "AI ëª¨ë¸ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        
        try:
            # ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
            context = "\\n".join([
                f"ë¬¸ì„œ {i+1}: {doc['title']}\\n{doc['text'][:200]}..."
                for i, doc in enumerate(documents)
            ])
            
            prompt = f"""
            ë‹¤ìŒ ë¬¸ì„œë“¤ì„ ì°¸ê³ í•˜ì—¬ ì§ˆë¬¸ì— ë‹µë³€í•´ì£¼ì„¸ìš”:
            
            ì§ˆë¬¸: {query}
            
            ì°¸ê³  ë¬¸ì„œ:
            {context}
            
            ë‹µë³€:
            """
            
            response = self.text_model.generate_content(prompt)
            return response.text
            
        except Exception as e:
            print(f"âŒ ë‹µë³€ ìƒì„± ì‹¤íŒ¨: {str(e)}")
            return f"ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
    
    def run_pipeline(self, query):
        """ì „ì²´ RAG íŒŒì´í”„ë¼ì¸ ì‹¤í–‰"""
        try:
            # 1. ë¬¸ì„œ ê²€ìƒ‰
            documents = self.search_documents(query)
            
            # 2. ë‹µë³€ ìƒì„±
            answer = self.generate_answer(query, documents)
            
            return {
                "query": query,
                "answer": answer,
                "sources": documents,
                "method": "vertex_ai_direct"
            }
            
        except Exception as e:
            return {"error": str(e)}

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    try:
        pipeline = VertexAIRAGPipeline(
            project_id="persona-diary-service",
            dataset_id="nebula_con_kaggle"
        )
        
        # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
        test_query = "What are the latest trends in AI?"
        result = pipeline.run_pipeline(test_query)
        
        print("âœ… Vertex AI RAG íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
        print(f"ì§ˆë¬¸: {result['query']}")
        print(f"ë‹µë³€: {result['answer'][:100]}...")
        
        return 0
        
    except Exception as e:
        print(f"âŒ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì‹¤íŒ¨: {str(e)}")
        return 1

if __name__ == "__main__":
    exit(main())
'''
        
        # íŒŒì¼ ì €ì¥
        with open('vertex_ai_rag_pipeline.py', 'w', encoding='utf-8') as f:
            f.write(pipeline_code)
        
        print("âœ… ëŒ€ì•ˆ RAG íŒŒì´í”„ë¼ì¸ ìƒì„± ì™„ë£Œ: vertex_ai_rag_pipeline.py")
        return True
        
    except Exception as e:
        print(f"âŒ ëŒ€ì•ˆ RAG íŒŒì´í”„ë¼ì¸ ìƒì„± ì‹¤íŒ¨: {str(e)}")
        return False


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸš¨ í•´ê²°ì±… íƒìƒ‰ ì‹œì‘...")
    
    try:
        # 1. ì§„ë‹¨ ê²°ê³¼ ë¶„ì„
        report = analyze_diagnostic_results()
        if not report:
            return 1
        
        # 2. í•´ê²° ê²½ë¡œ íƒìƒ‰
        explore_solution_paths()
        
        # 3. Vertex AI ëŒ€ì•ˆ í…ŒìŠ¤íŠ¸
        test_vertex_ai_alternatives()
        
        # 4. ëŒ€ì•ˆ RAG íŒŒì´í”„ë¼ì¸ ìƒì„±
        create_alternative_rag_pipeline()
        
        print("\nğŸ¯ í•´ê²°ì±… íƒìƒ‰ ì™„ë£Œ!")
        print("ğŸ“‹ ë‹¤ìŒ ë‹¨ê³„:")
        print("  1. vertex_ai_rag_pipeline.py ì‹¤í–‰ í…ŒìŠ¤íŠ¸")
        print("  2. GCP ì½˜ì†”ì—ì„œ API í™œì„±í™” í™•ì¸")
        print("  3. í•´ì»¤í†¤ ìš´ì˜ì§„ì—ê²Œ ë¬¸ì˜")
        
        return 0
        
    except Exception as e:
        print(f"âŒ í•´ê²°ì±… íƒìƒ‰ ì‹¤íŒ¨: {str(e)}")
        return 1


if __name__ == "__main__":
    exit(main()) 