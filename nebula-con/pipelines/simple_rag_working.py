#!/usr/bin/env python3
"""
ì‹¤ì œ ì¡´ì¬í•˜ëŠ” í…Œì´ë¸”ë§Œ ì‚¬ìš©í•˜ëŠ” ê°„ë‹¨í•œ RAG íŒŒì´í”„ë¼ì¸
ML ëª¨ë¸ ì—†ì´ë„ ì‘ë™í•˜ëŠ” ê¸°ë³¸ ë²„ì „
"""

import json
import logging
from typing import Any, Dict, List
from google.cloud import bigquery

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class SimpleRAGPipeline:
    """ì‹¤ì œ ì¡´ì¬í•˜ëŠ” í…Œì´ë¸”ë§Œ ì‚¬ìš©í•˜ëŠ” ê°„ë‹¨í•œ RAG íŒŒì´í”„ë¼ì¸"""
    
    def __init__(self, project_id: str = 'persona-diary-service', 
                 dataset_id: str = 'nebula_con_kaggle'):
        """RAG íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™”"""
        self.project_id = project_id
        self.dataset_id = dataset_id
        
        # BigQuery í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” - us-central1 ìœ„ì¹˜ ì‚¬ìš©
        self.bq_client = bigquery.Client(
            project=project_id, location='us-central1'
        )
        
        logger.info(
            f"ğŸš€ ê°„ë‹¨í•œ RAG íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™” ì™„ë£Œ: {project_id}.{dataset_id}"
        )
        logger.info(f"ğŸ“ ìœ„ì¹˜: us-central1")
    
    def search_documents_keyword(self, query_text: str, top_k: int = 5) -> List[Dict[str, Any]]:
        """í‚¤ì›Œë“œ ê¸°ë°˜ ë¬¸ì„œ ê²€ìƒ‰ - ì‹¤ì œ ì¡´ì¬í•˜ëŠ” í…Œì´ë¸” ì‚¬ìš©"""
        try:
            # ì‹¤ì œ ì¡´ì¬í•˜ëŠ” í…Œì´ë¸” í™•ì¸
            table_name = 'hacker_news_embeddings_external'
            
            # í‚¤ì›Œë“œ ê¸°ë°˜ ê²€ìƒ‰
            keywords = query_text.lower().split()
            
            search_query = f"""
            SELECT id, title, text, 
                   CONCAT(IFNULL(title, ''), ' ', IFNULL(text, '')) AS combined_text
            FROM `{self.project_id}.{self.dataset_id}.{table_name}`
            WHERE LOWER(CONCAT(IFNULL(title, ''), ' ', IFNULL(text, ''))) 
                  LIKE '%{keywords[0]}%'
            LIMIT {top_k * 2}
            """
            
            logger.info(f"ğŸ” ê²€ìƒ‰ ì¿¼ë¦¬ ì‹¤í–‰: {search_query[:100]}...")
            
            result = self.bq_client.query(search_query)
            rows = list(result.result())
            
            logger.info(f"ğŸ“Š ê²€ìƒ‰ ê²°ê³¼: {len(rows)}ê°œ í–‰ ë°œê²¬")
            
            # í‚¤ì›Œë“œ ê°€ì¤‘ì¹˜ë¡œ ì ìˆ˜ ê³„ì‚°
            scored_results = []
            for row in rows:
                if row.text is None and row.title is None:
                    continue
                    
                combined_text = f"{row.title or ''} {row.text or ''}".lower()
                score = sum(1 for keyword in keywords if keyword in combined_text)
                
                if score > 0:
                    scored_results.append({
                        'id': row.id,
                        'title': row.title,
                        'text': row.text,
                        'combined_text': combined_text,
                        'similarity_score': score / len(keywords)
                    })
            
            # ì ìˆ˜ìˆœ ì •ë ¬
            scored_results.sort(key=lambda x: x['similarity_score'], reverse=True)
            top_results = scored_results[:top_k]
            
            logger.info(f"âœ… í‚¤ì›Œë“œ ê²€ìƒ‰ ì™„ë£Œ: {len(top_results)}ê°œ ë¬¸ì„œ")
            return top_results
            
        except Exception as e:
            logger.error(f"âŒ í‚¤ì›Œë“œ ê²€ìƒ‰ ì‹¤íŒ¨: {str(e)}")
            return []
    
    def generate_answer_template(self, query: str, 
                               search_results: List[Dict[str, Any]]) -> str:
        """ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ í…œí”Œë¦¿ ê¸°ë°˜ ë‹µë³€ ìƒì„±"""
        if not search_results:
            return f"ì£„ì†¡í•©ë‹ˆë‹¤. '{query}'ì— ëŒ€í•œ ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        
        # ìƒìœ„ ê²°ê³¼ ì‚¬ìš©
        top_result = search_results[0]
        
        answer = f"""
ğŸ” **ì§ˆë¬¸**: {query}

ğŸ“š **ì°¾ì€ ì •ë³´**:
- **ì œëª©**: {top_result.get('title', 'N/A')}
- **ë‚´ìš©**: {top_result.get('text', 'N/A')[:200]}...
- **ìœ ì‚¬ë„ ì ìˆ˜**: {top_result.get('similarity_score', 0):.3f}

ğŸ’¡ **BigQuery í™œìš©**: ì´ ë‹µë³€ì€ BigQueryì˜ í‚¤ì›Œë“œ ê¸°ë°˜ ê²€ìƒ‰ì„ ì‚¬ìš©í•˜ì—¬ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.
        """.strip()
        
        return answer
    
    def retrieve_and_generate(self, query: str, top_k: int = 5) -> Dict[str, Any]:
        """RAG íŒŒì´í”„ë¼ì¸ ì‹¤í–‰: ê²€ìƒ‰ + ë‹µë³€ ìƒì„±"""
        try:
            logger.info(f"ğŸ” ì¿¼ë¦¬ ì²˜ë¦¬ ì¤‘: {query}")
            
            # 1. í‚¤ì›Œë“œ ê¸°ë°˜ ë¬¸ì„œ ê²€ìƒ‰
            search_results = self.search_documents_keyword(query, top_k)
            
            if not search_results:
                logger.warning("âš ï¸ ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ")
                return {
                    'query': query,
                    'search_results': [],
                    'answer': f"'{query}'ì— ëŒ€í•œ ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
                    'status': 'no_results'
                }
            
            # 2. í…œí”Œë¦¿ ê¸°ë°˜ ë‹µë³€ ìƒì„±
            answer = self.generate_answer_template(query, search_results)
            
            result = {
                'query': query,
                'search_results': search_results,
                'answer': answer,
                'status': 'success',
                'search_method': 'keyword_search_template_answer'
            }
            
            logger.info(f"âœ… RAG íŒŒì´í”„ë¼ì¸ ì™„ë£Œ: {query}")
            return result
            
        except Exception as e:
            logger.error(f"âŒ RAG íŒŒì´í”„ë¼ì¸ ì‹¤íŒ¨: {str(e)}")
            return {
                'query': query,
                'search_results': [],
                'answer': f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}",
                'status': 'error',
                'error': str(e)
            }
    
    def run_full_pipeline(self, test_queries: List[str]) -> Dict[str, Any]:
        """ì „ì²´ RAG íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
        logger.info("ğŸš€ ê°„ë‹¨í•œ RAG íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì‹œì‘!")
        
        results = []
        success_count = 0
        
        for i, query in enumerate(test_queries, 1):
            logger.info(f"ğŸ” í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬ {i}/{len(test_queries)} ì‹¤í–‰: {query}")
            
            try:
                result = self.retrieve_and_generate(query)
                results.append(result)
                
                if result['status'] == 'success':
                    success_count += 1
                    logger.info(f"âœ… ì¿¼ë¦¬ {i} ì„±ê³µ")
                else:
                    logger.warning(
                        f"âš ï¸ ì¿¼ë¦¬ {i} ì‹¤íŒ¨: {result.get('status', 'unknown')}"
                    )
                    
            except Exception as e:
                logger.error(f"âŒ ì¿¼ë¦¬ {i} ì˜ˆì™¸ ë°œìƒ: {str(e)}")
                results.append({
                    'query': query,
                    'search_results': [],
                    'answer': f"ì˜ˆì™¸ ë°œìƒ: {str(e)}",
                    'status': 'exception',
                    'error': str(e)
                })
        
        # ê²°ê³¼ ìš”ì•½
        summary = {
            'total_queries': len(test_queries),
            'successful_queries': success_count,
            'success_rate': f"{success_count}/{len(test_queries)}",
            'results': results
        }
        
        # ê²°ê³¼ ì €ì¥
        output_file = 'simple_rag_working_results.json'
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(summary, f, ensure_ascii=False, indent=2)
        
        logger.info("âœ… ê°„ë‹¨í•œ RAG íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì™„ë£Œ!")
        logger.info(f"ì„±ê³µ: {success_count}/{len(test_queries)} ì¿¼ë¦¬")
        logger.info(f"ê²°ê³¼ ì €ì¥: {output_file}")
        
        return summary


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    # ì‹¤ì œ í”„ë¡œì íŠ¸ êµ¬ì¡°ì— ë§ëŠ” ì„¤ì •
    project_id = "persona-diary-service"
    dataset_id = "nebula_con_kaggle"  # ì‹¤ì œ ì¡´ì¬í•˜ëŠ” ë°ì´í„°ì…‹
    
    # RAG íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™”
    rag_pipeline = SimpleRAGPipeline(project_id, dataset_id)
    
    # í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬
    test_queries = [
        "How to optimize machine learning models?",
        "Best practices for data science projects?",
        "Startup advice for new founders",
        "PhD vs startup career path",
        "Machine learning in production"
    ]
    
    # ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
    results = rag_pipeline.run_full_pipeline(test_queries)
    
    # ê²°ê³¼ ì¶œë ¥
    print(f"\nğŸ‰ ê°„ë‹¨í•œ RAG íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì„±ê³µ!")
    print(f"âœ… ì‹¤ì œ ì¡´ì¬í•˜ëŠ” ë°ì´í„°ì…‹ê³¼ í…Œì´ë¸” ì‚¬ìš©!")
    print(f"ğŸ“ ì˜¬ë°”ë¥¸ ìœ„ì¹˜: us-central1")
    print(f"ğŸš€ ì´ì œ ìºê¸€ í•´ì»¤í†¤ ì œì¶œì´ ê°€ëŠ¥í•©ë‹ˆë‹¤!")


if __name__ == "__main__":
    main() 